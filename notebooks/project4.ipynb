{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Project 4: Natural Language Processing \n---\n\n**Group 9: Aidan Stocks, Hugo Reinicke, Nicola Clark, Jonas-Mika Senghaas**\n\nSubmission: *03.06.2021* / Last Modified: *02.06.2021*\n\n---\n\nThis notebook contains the step-by-step process of building a natural language machine learning model to automatically detect *(a)* Hatespeech and *(b)* Emotion in tweets on the social network Twitter. \n\nThe initial data was obtained from the [TweetEval](https://github.com/cardiffnlp/tweeteval#evaluating-your-system) GitHub repository, that provides data for supervised training of classifiers for natural language processing, more specifically it provides prepared data for several mini-project involving the analysis of different characteristics of tweets.",
   "metadata": {
    "cell_id": "00000-8f8eb98f-2a98-41af-9825-5a8a8c441dee",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Introduction\n---\nSocial media is omnipresent in today's world. We use messengers to communicate, share pictures, music, thoughts - in short - our life on the internet with people that are close, and maybe also not as close to us. Twitter is one of those social networks. The american social networking service allows its users to post and interact with messages known as through so-called tweets. 280 character postings on the online-service that can be liked, commented, threaded and shared. Since its launch in 2006, *Twitter* has grown massively, nowadays reporting hundreds of million of users. Besides its diverse utilisation, Twitter is especially known for a platform for political discussion. Both politicians and society use Twitter as a channel to take positions in politcal debates and express opinion. \n\nWhile this is desirable and embracing the idea of free-speech on the internet, the question of whether or not Twitter should use tools to automatically detect unwanted content from its platform, such as racism, sexism, false information or hatespeech, is a subject of on-going public debate. \n\nThis project, in a first instance, sets aside the ethical challenges and questions arising, and solely focuses on the technical details of how such a solution might work. The goal of this project is to optimise a machine learning model to automatically detect unwanted content.",
   "metadata": {
    "cell_id": "00001-5fcfa044-05ac-485a-8293-0db98813ff5e",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Running this Notebook\n---\nThis notebook contains all code to reproduce the findings of the project as can be seen on the [GitHub](https://github.com/jonas-mika/fyp2021p04g09) page of this project. In order to read in the data correctly, the global paths configured in the section `Constants` need to be correct. The following file structure - as prepared in the `submission.zip` - was followed throughout the project and is recommended to use (alternatively the paths in the section `Constants` can be adjusted):\n\n```\n*project tree structure*\n```\n*Note that the rest of the file structure as can be seen on the [GitHub](https://github.com/jonas-mika/fyp2021p03g09) page of the project generates automatically*",
   "metadata": {
    "cell_id": "00002-e3f8c8e5-1dc7-47ff-9108-2450997c051c",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Required Libraries and Further Imports\n---\nThroughout the project, we will use a range of both built-in and external Python libraries. This notebook will only run if all libraries and modules are correctly installed on your local machines. \nTo install missing packages use `pip install <package_name>` (PIP (Python Package Index) is the central package management system, read more [here](https://pypi.org/project/pip/)). \n\nIn case you desire further information about the used packages, click the following links to find detailed documentations:\n- [Pandas](https://pandas.pydata.org/)\n- [Numpy](https://numpy.org/)\n- [Matplotlib](https://matplotlib.org/stable/index.html)\n- [SciKit Learn](https://scikit-learn.org/stable/)\n- [NLTK](https://www.nltk.org/)",
   "metadata": {
    "cell_id": "00003-8f195f8a-4025-446a-8b44-300b55666211",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00004-cf13b571-fc4d-40f4-8617-43224164fcb8",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 7159,
    "execution_start": 1622701480675,
    "output_cleared": true,
    "source_hash": "2841754f",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "%%capture\n# uncomment lines with uninstalled packages\n\n#!pip install -U numpy pandas matplotlib seaborn skikit-learn \n!pip install pycontractions\n!pip install imblearn\n!pip install statsmodels",
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00005-9cbe0305-7f30-486b-be81-0c10af861246",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2136,
    "execution_start": 1622701487838,
    "output_cleared": false,
    "source_hash": "d0a72a8f",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "# python standard libraries\nimport json                                            # data transfer to and from json format\nimport os                                              # access operating system from python\nimport math                                            # mathematical operations in python\nimport random                                          # creates randomness\nimport re                                              # regex search in python\nimport shutil                                          # system control in python\nimport warnings                                        # ignore annoying warnings\nwarnings.filterwarnings(\"ignore\")\n\n# external libraries\nimport numpy as np                                     # used for numerical calculations and fast array manipulations\nimport pandas as pd                                    # provides major datastructure pd.DataFrame() to store datasets\nimport matplotlib\nimport matplotlib.pyplot as plt                        # basic data visualisation\nfrom matplotlib.ticker import MaxNLocator\nimport seaborn as sns   \n                           # advanced data visualisation\nfrom nltk.tokenize import TweetTokenizer               # tokeniser api\nfrom nltk.corpus import stopwords\nimport nltk    \nnltk.download('stopwords');\nfrom pycontractions import Contractions                # intelligently expands contractions in natural language\nfrom collections import Counter                        # counts objects",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "text": "[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00006-16d5cbf8-01cc-41a9-9fa2-dbbfdc49a2d0",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "78c7edf6",
    "execution_start": 1622701489980,
    "execution_millis": 96,
    "output_cleared": true,
    "deepnote_cell_type": "code"
   },
   "source": "# feature extraction\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer  # not used yet\n\n# addressing imbalance in data\nfrom imblearn.over_sampling import RandomOverSampler as ROS\n\n# classifiers\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\n# performance evaluation\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n\nfrom sklearn.metrics import cohen_kappa_score\nfrom statsmodels.stats.inter_rater import fleiss_kappa",
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00006-5afa390e-a19c-4f7b-b2f5-752fba00777d",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 22,
    "execution_start": 1622701490084,
    "output_cleared": false,
    "source_hash": "9a25b5af",
    "deepnote_cell_type": "code"
   },
   "source": "print(f'Numpy Version: {np.__version__}')\nprint(f'Pandas Version: {pd.__version__}')\nprint(f'Matplotlib Version: {matplotlib.__version__}')\nprint(f'Seaborn Version: {sns.__version__}')",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": "Numpy Version: 1.19.5\nPandas Version: 1.2.4\nMatplotlib Version: 3.4.2\nSeaborn Version: 0.11.1\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Constants\n---\nTo enhance readibilty, as well as to decrease the maintenance effort, it is useful for bigger projects to define contants that need to be accessed globally throughout the whole notebook in advance. \nThe following cell contains all of those global constants. By convention, we write them in caps (https://www.python.org/dev/peps/pep-0008/#constants)",
   "metadata": {
    "cell_id": "00008-4f347db9-f433-4a57-9e83-4fbb27586617",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00010-18532f0a-c77d-42e2-b487-aa327b69dc04",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1622701490088,
    "output_cleared": true,
    "source_hash": "74c0338e",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "PREPROCESS_DATA = False\nGENERATE_IAA_SAMPLE = False",
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00009-d56d40bc-118b-4ddd-b029-25d968bcf22d",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "52cd5b5a",
    "execution_start": 1622701490113,
    "execution_millis": 0,
    "output_cleared": true,
    "deepnote_cell_type": "code"
   },
   "source": "random.seed(1)",
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00009-8c033e56-02ab-48b7-9eff-1efefe08d35c",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1622701490113,
    "output_cleared": true,
    "source_hash": "d3d11c4b",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "DATASETS = ['hate', 'emotion']\n\n# store paths\nPATH = {}\nPATH['data'] = {}\nPATH['data']['raw'] = \"../data/raw/\"\nPATH['data']['processed'] = \"../data/processed/\"\n\n# store data \nDATA = {}\nDATA['raw'] = {}\nDATA['processed'] = {}\nfor dataset in DATASETS:\n    DATA['raw'][dataset] = {}\n    DATA['processed'][dataset] = {}\n\nCORPUS = {}\nVOCABULARY = {}",
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Fetching Data\n---\n*TASK 0*\n\nAfter having setup the overall scheme of the project, we need to fetch the data we want to work on. The datasets were obtained from the\n[TweetEval](https://github.com/cardiffnlp/tweeteval#evaluating-your-system) GitHub repository, which provides ready-to-work on tweets and gold-standard annotations for different focuses of analysis - already split up into training, validation and testing sets.\n\n1. Binary Classifcation: **Hate-Speech**\n > Two Labels: *Hate-Speech*/ *Not Hate-Speech*\n\n > [Raw Data (GitHub)](https://github.com/cardiffnlp/tweeteval/tree/main/datasets/hate)\n\n2. Multiclass Classification: **Emotion Recognition**  \n >Four Labels: *Anger*, *Joy*, *Sadness*, *Optimism* \n\n >[Raw Data (GitHub)](https://github.com/cardiffnlp/tweeteval/tree/main/datasets/emotion)\n\n*Note, in order to fetch this data into the Jupyter, the above-mentioned files need to be in the existent in the file structure and the location specified in the code and file tree structure in the introductory section. This should be the case in the submission and if this project was pulled or forked directly from [GitHub](https://github.com/jonas-mika/fyp2021p04g09)* ",
   "metadata": {
    "cell_id": "00010-30f29e03-2c93-4a41-9cdd-c63ddcf81385",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Loading in Data\n---\nWe start off by loading in the data obtained from the above-mentioned sources into the script. All tweets are being read into a list of strings, where each string is representing a single tweet. The golden labels are being read into an index-corresponding array of integers, where the integer at *i*th position is the gold label for the tweet in the list of tweets at position *i*. Lastly, we read in the mapping, between the integer and the corresonding label into a dictionary, such that we can use it for nice plotting.",
   "metadata": {
    "cell_id": "00012-517a92e6-641e-4b58-ae16-4fc3f1dc0f0c",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00011-d60e995b-fcb6-4868-b5f3-bead2a4d235a",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1622701490114,
    "output_cleared": true,
    "source_hash": "e386fa8c",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "# helper function to read in raw files correctly\ndef read_raw_input(dataset):\n    # reading in all .txts into list of strings\n    for _file in os.listdir(f'../data/raw/{dataset}'):\n        with open(f'../data/raw/{dataset}/{_file}', 'r', encoding='UTF-8') as infile:\n            DATA['raw'][dataset][_file[:-4]] = [line.strip() for line in infile.readlines()]\n\n    # convert target labels to integers\n    for key in ['train_labels', 'val_labels', 'test_labels']:\n        DATA['raw'][dataset][key] = [int(x) for x in DATA['raw'][dataset][key]]\n\n    # convert mapping to dictionary\n    DATA['raw'][dataset]['mapping'] = {int(string.split('\\t')[0]): string.split('\\t')[1] for string in DATA['raw'][dataset]['mapping']}",
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00014-a564b5fd-9112-40ea-ab20-a9e06cef672c",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 66,
    "execution_start": 1622701490115,
    "output_cleared": true,
    "scrolled": false,
    "source_hash": "32dcc143",
    "deepnote_cell_type": "code"
   },
   "source": "# read in the the raw data as specified above for both the hate and emotion data\nfor dataset in DATASETS:\n    read_raw_input(dataset)",
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Exploring Data\n---\nLet's get a feeling for what kind of data we are dealing with. For now, we simply peek into our actual data, the tweets, and output them with their corresponding gold label. After that, we plot the distribution of the labels, which is an important characteristic of the training process, since it might reveal possible imbalances that need to be addressed before training a model.",
   "metadata": {
    "cell_id": "00015-6ac2c66d-4d76-4711-82ed-29c0f25e3314",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Data Size\n---\nBefore starting to tackle the specific data, we should get a feeling with what size of data we are dealing with. Especially in NLP this is an important step, since NLP models usually incorporate high amounts of data in order to build well-performing models.",
   "metadata": {
    "tags": [],
    "cell_id": "00016-304c396c-0e65-4df0-947d-87cee089d03f",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00017-ac745fa2-4c9e-4367-8bde-fb896f797948",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "8c443e46",
    "execution_start": 1622701490186,
    "execution_millis": 572,
    "output_cleared": false,
    "deepnote_cell_type": "code"
   },
   "source": "!ls -lh ../data/raw/hate",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "text": "total 1.2M\r\n-rwxr-xr-x 1 root root   17 May  4 14:32 mapping.txt\r\n-rwxr-xr-x 1 root root 5.9K May  4 14:32 test_labels.txt\r\n-rwxr-xr-x 1 root root 390K May  4 14:32 test_text.txt\r\n-rwxr-xr-x 1 root root  18K May  4 14:32 train_labels.txt\r\n-rwxr-xr-x 1 root root 1.1M May  4 14:32 train_text.txt\r\n-rwxr-xr-x 1 root root 2.0K May  4 14:32 val_labels.txt\r\n-rwxr-xr-x 1 root root 141K May  4 14:32 val_text.txt\r\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00018-bb627de0-990f-4914-acb7-a5f7583e5420",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "a31cd803",
    "execution_start": 1622701490793,
    "execution_millis": 550,
    "output_cleared": false,
    "deepnote_cell_type": "code"
   },
   "source": "!ls -lh ../data/raw/emotion",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "text": "total 343K\r\n-rw-r--r-- 1 root root   34 May  4 14:32 mapping.txt\r\n-rw-r--r-- 1 root root 2.8K May  4 14:32 test_labels.txt\r\n-rw-r--r-- 1 root root 130K May  4 14:32 test_text.txt\r\n-rw-r--r-- 1 root root 6.4K May  4 14:32 train_labels.txt\r\n-rw-r--r-- 1 root root 300K May  4 14:32 train_text.txt\r\n-rw-r--r-- 1 root root  748 May  4 14:32 val_labels.txt\r\n-rw-r--r-- 1 root root  34K May  4 14:32 val_text.txt\r\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "As can be seen, the file sizes are considerably small for NLP datasets. This means, that we most likely will be able to work with the data on local memory. However, we are trying to follow best practice and work RAM efficient during the project.",
   "metadata": {
    "tags": [],
    "cell_id": "00019-0358f284-28d9-49ce-b191-7919bcfad280",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00020-f3ee83e4-95f6-4de1-a828-697178c1a0b7",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "d8f1efc2",
    "execution_start": 1622701491335,
    "execution_millis": 576,
    "output_cleared": false,
    "deepnote_cell_type": "code"
   },
   "source": "!wc -l ../data/raw/hate/*_text.txt",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "text": "   2970 ../data/raw/hate/test_text.txt\r\n   9000 ../data/raw/hate/train_text.txt\r\n   1000 ../data/raw/hate/val_text.txt\r\n  12970 total\r\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00021-bc546d23-a932-4068-abac-00a0132e9d23",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "40594db",
    "execution_start": 1622701491918,
    "execution_millis": 649,
    "output_cleared": false,
    "deepnote_cell_type": "code"
   },
   "source": "!wc -l ../data/raw/emotion/*_text.txt",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "text": "  1421 ../data/raw/emotion/test_text.txt\r\n  3257 ../data/raw/emotion/train_text.txt\r\n   374 ../data/raw/emotion/val_text.txt\r\n  5052 total\r\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "The `hate` dataset contains more than double the tweets than the `emotion` dataset. However, the split is rather similar in both instances with a roughly 70-20-10 split for training, testing and validation.",
   "metadata": {
    "tags": [],
    "cell_id": "00022-4651d104-1cb3-4f44-a9fc-3ef8673a049d",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Visualising Raw Data\n---",
   "metadata": {
    "cell_id": "00016-1ade1bb5-34a5-4a97-9049-49dbb00ee154",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00017-8c456ad3-3f69-4ec0-931f-2fdc6fe0e33e",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 33,
    "execution_start": 1622701492534,
    "output_cleared": false,
    "source_hash": "4847394d",
    "deepnote_cell_type": "code"
   },
   "source": "# hate\nfor i in range(10):\n    print(f\"{i+1}\\tLabel: {DATA['raw']['hate']['mapping'][DATA['raw']['hate']['train_labels'][i]].title()}\\t\\t{DATA['raw']['hate']['train_text'][i]}\")",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "text": "1\tLabel: Not-Hate\t\t@user nice new signage. Are you not concerned by Beatlemania -style hysterical crowds crongregating on youâ€¦\n2\tLabel: Hate\t\tA woman who you fucked multiple times saying yo dick small is a compliment you know u hit that spot ðŸ˜Ž\n3\tLabel: Hate\t\t@user @user real talk do you have eyes or were they gouged out by a rapefugee?\n4\tLabel: Hate\t\tyour girlfriend lookin at me like a groupie in this bitch!\n5\tLabel: Not-Hate\t\tHysterical woman like @user\n6\tLabel: Not-Hate\t\tMe flirting- So tell me about your father...\n7\tLabel: Not-Hate\t\tThe Philippine Catholic bishops' work for migrant workers should focus on families who are \"paying the great...\n8\tLabel: Hate\t\tI AM NOT GOING AFTER YOUR EX BF YOU LIEING SACK OF SHIT ! I'm done with you dude that's why I dumped your ass cause your a lieing ðŸ˜‚ðŸ˜¡ bitch\n9\tLabel: Not-Hate\t\tWhen cuffin season is finally over\n10\tLabel: Hate\t\tSend home migrants not in need of protection, Peter Dutton tells UN, HEY DUTTON HOW ABOUT THE ONES THAT HAVE STAYED AND NOT LEFT THE COUNTRY WHEN THEY SHOULD OVERSTAYERS ? WHY DONT YOU GO AND ROUND ALL THEM UP ?\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "The first ten tweets from the training set of the hatespeech task look as expected. Tweets are a single-line string, including emojis, syntax, grammar and spelling of the orginal tweet. Both the author of the tweet and links to other users, however, are anonymised for data privacy reasons. \n\nThe gold standard labels appear reasonable for the first ten tweets.",
   "metadata": {
    "tags": [],
    "cell_id": "00017-8efa9570-f2fb-44cd-bdb4-33f75960603e",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00018-f6587a74-f6da-4c6c-8540-db447f5615d9",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 24,
    "execution_start": 1622701492543,
    "output_cleared": false,
    "source_hash": "c303da21",
    "deepnote_cell_type": "code"
   },
   "source": "# emotion\nfor i in range(10):\n    print(f\"{i+1}\\tLabel: {DATA['raw']['emotion']['mapping'][DATA['raw']['emotion']['train_labels'][i]].title()}\\t\\t{DATA['raw']['emotion']['train_text'][i]}\")",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "text": "1\tLabel: Optimism\t\tâ€œWorry is a down payment on a problem you may never have'. Â Joyce Meyer.  #motivation #leadership #worry\n2\tLabel: Anger\t\tMy roommate: it's okay that we can't spell because we have autocorrect. #terrible #firstworldprobs\n3\tLabel: Joy\t\tNo but that's so cute. Atsu was probably shy about photos before but cherry helped her out uwu\n4\tLabel: Anger\t\tRooneys fucking untouchable isn't he? Been fucking dreadful again, depay has looked decent(ish)tonight\n5\tLabel: Sadness\t\tit's pretty depressing when u hit pan on ur favourite highlighter\n6\tLabel: Anger\t\t@user but your pussy was weak from what I heard so stfu up to me bitch . You got to threaten him that your pregnant .\n7\tLabel: Sadness\t\tMaking that yearly transition from excited and hopeful college returner to sick and exhausted pessimist. #college\n8\tLabel: Joy\t\tTiller and breezy should do a collab album. Rapping and singing prolly be fire\n9\tLabel: Anger\t\t@user broadband is shocking regretting signing up now #angry #shouldofgonewithvirgin\n10\tLabel: Anger\t\t@user Look at those teef! #growl\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "The data for the emotion recognition looks similar. Again, tweets are a single-line string, including emojis, syntax, grammar and spelling of the orginal tweet. Both the author of the tweet and links to other users are anonymised for data privacy reasons. \n\nAlso here, the gold standard labels appear reasonable for the first ten tweets.",
   "metadata": {
    "tags": [],
    "cell_id": "00019-aca6c04c-c1b1-43a8-a6d4-916bedefb0ac",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Visualising Label Distribution\n---\nVisualising the distribution of the target variable in any classification task is an important first step in order to evluate the quality of the data we are training on. Ideally, we would like to observe equally balanced labels, since this prevents models from being overly biased by always predicting a dominant labels. ",
   "metadata": {
    "cell_id": "00019-ac0093ee-cb8e-4df0-9240-28b8639da8f0",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00020-ff2b603d-7d95-43b5-8411-7c54ff2985ec",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4,
    "execution_start": 1622701492552,
    "output_cleared": true,
    "source_hash": "56ff2033",
    "deepnote_cell_type": "code"
   },
   "source": "# helper function to plot the distribution of labels in all splits of the data\ndef visualise_label_distribution(dataset):\n    # initalise figure with three axes\n    fig, ax = plt.subplots(ncols=3, figsize=(12,4))\n    fig.suptitle(f'Frequency of Target Label in {dataset.capitalize()}', fontsize=12, fontweight='bold') # global title\n\n    # plot barplot of label distribution with some additional aesthetic adjustment in each split of the data\n    for i, key in enumerate(['train_labels', 'val_labels', 'test_labels']):\n        label, count = np.unique(DATA['raw'][dataset][key], return_counts=True)\n        ax[i].bar(label, count, color='grey');\n        ax[i].set_title(key.replace('_', ' ').title())\n        ax[i].set_xticks(label); ax[i].set_xticklabels([string.title() for string in DATA['raw'][dataset]['mapping'].values()])",
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00021-046d0488-77dc-47d3-a29c-d178ea704a1f",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 267,
    "execution_start": 1622701492597,
    "output_cleared": false,
    "source_hash": "894be1c8",
    "deepnote_cell_type": "code"
   },
   "source": "visualise_label_distribution(dataset='hate')",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 864x288 with 3 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light",
      "image/png": {
       "width": 716,
       "height": 277
      }
     },
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "The binary label *Hate* (42%) or *Non-Hate* (58%) seems reasonably balanced. Here, balancing of the labels before building the model is possible, but not mandatory. It furthermore becomes obvious that the label ratio is consistent across all splits (training, validation and testing set).",
   "metadata": {
    "tags": [],
    "cell_id": "00023-e661d70e-826c-4fd1-985d-a284c26e7f7e",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00022-83c0ec2d-8094-4123-8603-caad77edb2af",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 334,
    "execution_start": 1622701492872,
    "output_cleared": false,
    "source_hash": "c0926180",
    "deepnote_cell_type": "code"
   },
   "source": "visualise_label_distribution(dataset='emotion')",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 864x288 with 3 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light",
      "image/png": {
       "width": 716,
       "height": 277
      }
     },
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "However, in the multi-class classifcation task we observe a high imbalance. With only 9% of the total amount of data in each split, the label *optimism* is underrepresent, while the label *anger* (43%) is overrepresented. This imbalance needs to be addressed before training our classifiers. \nAgain, however, we observe a consistent label ratio across all splits. ",
   "metadata": {
    "tags": [],
    "cell_id": "00025-fb419f6b-91d7-4063-b2b8-e7462b3b68f1",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "# Processing of Language Data\n---\n*TASK 1*\n\nNatural language is a highly-complex type of data, that needs to be processed before it can be implented meaningfully into a classification task. For natural language classifiers the main step of processing the raw data - the original tweets - is called **tokenisation**.\n\nOn a high level, computers stand no chance in understanding language. After all, each and every tweet we are dealing with is just a unique concatenation of 0's and 1's, that in itself is useless for classifying the tweet in any way. We must therefore transform our data in a way that our computer is able to understand it. This is done during the process of tokenisation in natural language processing. Tokenisation in NLP generally means the concept of breaking down the original data into smaller parts, called tokens. Those tokens could be sentences, one or more words, or even smaller chunks of text. Either way, they are used to built a vocabulary that ultimately results in a count vector machine, that serves as input to the machine learning model.",
   "metadata": {
    "cell_id": "00011-c1d3e256-83ab-4833-93bb-155c6dcb73ca",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Building Tokeniser\n---\nIn this project we chose to build a word-tokeniser, meaning that the ideal tokeniser recognises words and splits accordingly. However, due to the fact that we are working with tweet data, there are some special requirements in order to get optimal performance in our models. \n\n**Features of Tokeniser**\n\n1. Lowercase ()\n\n2. Links (Links are a core part of a tweet containing it - if not the core. To not lose information, we must include the links in our classification. However, for the classfication the actual link address is of minor importance. For this reason, we would like to recognise any link, then replace it with some dummy string that the model uses to classify any kind of link in a tweet.\n\n3. Emojis (Emojis have developed to a central method of communicating emotions. It is therefore important that our tokeniser recognises single emojis and feeds them into our classifier.)\n\n4. Hashtags ()\n\n4. Contractions (Has not or Hasn't? It means the same, so we would like our model to recognise the two as the same token.)\n",
   "metadata": {
    "cell_id": "00024-925deca3-bb20-43eb-bc18-98e47d7a5780",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "The following code cells contain how the tokeniser was built in this project. It is fundamentally based on the *Tweet Tokeniser* provided by the NLTK library and then adds additional functionality using both RegEx and another extyernally trained model for tokenising contractions correctly.",
   "metadata": {
    "tags": [],
    "cell_id": "00028-9ffd5945-a956-4a50-ae3e-2a5bafdbc89d",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00028-e796ec1e-9733-4523-b144-52042e24ba94",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "e6ca8f6a",
    "execution_start": 1622701493170,
    "execution_millis": 4,
    "output_cleared": true,
    "deepnote_cell_type": "code"
   },
   "source": "# loading pre-trained contraction model\nif PREPROCESS_DATA == True:\n    cont.load_models() # doesn't work on deepnote, because of memory issues. works locally\n\ncont = Contractions(api_key=\"glove-twitter-200\")",
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00043-2f55d04c-3946-4a00-a740-a8debdffb56c",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1622701493176,
    "output_cleared": true,
    "source_hash": "ba5dc7cf",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "# define url regex pattern and replace pattern globally (compile for speedup)\nurl_pattern = re.compile(r\"(?i)((?:https?://|www\\d{0,3}[.]|[a-z0-9.-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|(([^\\s()<>]+|(([^\\s()<>]+)))))+(?:(([^\\s()<>]+|(([^\\s()<>]+))))|[^\\s`!()[]{};:'\\\".,<>?Â«Â»\\â€œ\\â€â€˜â€™]))\")\ndummy = \" <=LINK=> \"\n\n# brush up functions\ndef remove_links(tweet):\n    return re.sub(url_pattern, dummy, tweet) # substituting dummy for every link\n\ndef remove_newline(tweet):\n    return re.sub(r'\\\\n', ' ', tweet) # deals with issue of newline characters within tweets\n\ndef expand(tweet):\n    return list(cont.expand_texts([tweet]))[0] # expands contractions",
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00031-69719e76-f2e4-4188-b5ef-2c510e3a7879",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "1b22e0bb",
    "execution_start": 1622701493187,
    "execution_millis": 1,
    "output_cleared": true,
    "deepnote_cell_type": "code"
   },
   "source": "tk = TweetTokenizer()\n\ndef tokenise(tweet):\n    cleaned_tweet = expand(remove_links(remove_newline(tweet.lower())))\n    return tk.tokenize(cleaned_tweet)",
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Exporting Tokenised Tweets\n---\nWe have built the final tokeniser that will be used throughout this project. To not stretch out the RAM, we iterate over the raw data tweet by tweet, tokenise it and write it into an external file. The final tokenised tweets will be separated by tabs, such that they can easily be read back in again, while keeping the split between tokens. \n\nFor both datasets, all processed files will be in saved into a subfolder called `hate` or `emotion` within the folder `processed` in `data`. While exporting, we maintain the naming convention of the raw data. This enables us to use the same function to read in the processed data again. \n\n*Note that directories are created automatically and thus do not need to be created by hand.*",
   "metadata": {
    "tags": [],
    "cell_id": "00032-066aa9d6-3735-4942-af9d-ed96974f73ed",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00046-8f2c5b62-9cce-4460-a430-78de3377ebca",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1622701493193,
    "output_cleared": true,
    "source_hash": "be8da45",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "if PREPROCESS_DATA == True:\n    for dataset in DATASETS:\n        # create preprocessed folder\n        try: os.makedirs(f'../data/processed/{dataset}')\n        except: None\n\n        # preprocess and tokenize tweets\n        for key in ['train_text', 'val_text', 'test_text']:\n            with open(f'../data/processed/{dataset}/{key}.txt', 'w', encoding = 'UTF-8') as outfile:\n                for tweet in DATA['raw'][dataset][key]:\n                    outfile.write('\\t'.join(tokenise(tweet)) + '\\n') # writing tokenised tweet with tab delimiter\n\n        # copy labels and mapping without preprocessing\n        for key in ['train_labels', 'val_labels', 'test_labels', 'mapping']:\n            shutil.copyfile(f'../data/raw/{dataset}/{key}.txt', f'../data/processed/{dataset}/{key}.txt')",
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00042-632ac15c-7d49-4503-b780-5829b6f5faac",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 256,
    "execution_start": 1622701493201,
    "output_cleared": true,
    "source_hash": "e8fcf339",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "# loading in processed data\nfor dataset in DATASETS:\n    for key in os.listdir(f'../data/processed/{dataset}'):\n        with open(f'../data/processed/{dataset}/{key}', 'r', encoding='UTF-8') as infile:\n            DATA['processed'][dataset][key[:-4]] = [line.strip().split('\\t') for line in infile.readlines()]\n\n    # convert target labels to integers\n    for key in ['train_labels', 'val_labels', 'test_labels']:\n        DATA['processed'][dataset][key] = [int(x) for x in [DATA['processed'][dataset][key][i][0] for i in range(len(DATA['processed'][dataset][key]))]]\n\n    # convert mapping to dictionary\n    DATA['processed'][dataset]['mapping'] = {int(string[0]): string[1] for string in DATA['processed'][dataset]['mapping']}",
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Testing Tokeniser\n---\nThe tokeniser is built and has been applied onto the entire corpus. Let's evaluate its performance using the same first ten tweets as we peeked into in the first section.",
   "metadata": {
    "tags": [],
    "cell_id": "00032-b6926ea2-8ec4-41b7-9bc5-f7558b5bb006",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00033-ee786581-47b7-48de-b8cf-a5f5a7c848dd",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "e752b4be",
    "execution_start": 1622701493464,
    "execution_millis": 47,
    "output_cleared": false,
    "deepnote_cell_type": "code"
   },
   "source": "for i in range(10):\n    print(f\"Original Tweet: {DATA['raw']['hate']['train_text'][i]}\\nTokenised Tweet: {'-'.join(DATA['processed']['hate']['train_text'][i])}\\n\")",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "text": "Original Tweet: @user nice new signage. Are you not concerned by Beatlemania -style hysterical crowds crongregating on youâ€¦\nTokenised Tweet: @user-nice-new-signage-.-are-you-not-concerned-by-beatlemania---style-hysterical-crowds-crongregating-on-you-â€¦\n\nOriginal Tweet: A woman who you fucked multiple times saying yo dick small is a compliment you know u hit that spot ðŸ˜Ž\nTokenised Tweet: a-woman-who-you-fucked-multiple-times-saying-yo-dick-small-is-a-compliment-you-know-you-hit-that-spot-ðŸ˜Ž\n\nOriginal Tweet: @user @user real talk do you have eyes or were they gouged out by a rapefugee?\nTokenised Tweet: @user-@user-real-talk-do-you-have-eyes-or-were-they-gouged-out-by-a-rapefugee-?\n\nOriginal Tweet: your girlfriend lookin at me like a groupie in this bitch!\nTokenised Tweet: your-girlfriend-lookin-at-me-like-a-groupie-in-this-bitch-!\n\nOriginal Tweet: Hysterical woman like @user\nTokenised Tweet: hysterical-woman-like-@user\n\nOriginal Tweet: Me flirting- So tell me about your father...\nTokenised Tweet: me-flirting---so-tell-me-about-your-father-...\n\nOriginal Tweet: The Philippine Catholic bishops' work for migrant workers should focus on families who are \"paying the great...\nTokenised Tweet: the-philippine-catholic-bishops-'-work-for-migrant-workers-should-focus-on-families-who-are-\"-paying-the-great-...\n\nOriginal Tweet: I AM NOT GOING AFTER YOUR EX BF YOU LIEING SACK OF SHIT ! I'm done with you dude that's why I dumped your ass cause your a lieing ðŸ˜‚ðŸ˜¡ bitch\nTokenised Tweet: i-am-not-going-after-your-ex-bf-you-lieing-sack-of-shit-!-I-am-done-with-you-dude-that-is-why-i-dumped-your-ass-because-your-a-lieing-ðŸ˜‚-ðŸ˜¡-bitch\n\nOriginal Tweet: When cuffin season is finally over\nTokenised Tweet: when-cuffin-season-is-finally-over\n\nOriginal Tweet: Send home migrants not in need of protection, Peter Dutton tells UN, HEY DUTTON HOW ABOUT THE ONES THAT HAVE STAYED AND NOT LEFT THE COUNTRY WHEN THEY SHOULD OVERSTAYERS ? WHY DONT YOU GO AND ROUND ALL THEM UP ?\nTokenised Tweet: send-home-migrants-not-in-need-of-protection-,-peter-dutton-tells-un-,-hey-dutton-how-about-the-ones-that-have-stayed-and-not-left-the-country-when-they-should-overstayers-?-why-do-not-you-go-and-round-all-them-up-?\n\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00038-66f6ec60-1a52-4324-91e7-4d0dd06c50e3",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "b23e6d6a",
    "execution_start": 1622701493478,
    "execution_millis": 33,
    "output_cleared": false,
    "deepnote_cell_type": "code"
   },
   "source": "for i in range(10):\n    print(f\"Original Tweet: {DATA['raw']['emotion']['train_text'][i]}\\nTokenised Tweet: {'-'.join(DATA['processed']['emotion']['train_text'][i])}\\n\")",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "text": "Original Tweet: â€œWorry is a down payment on a problem you may never have'. Â Joyce Meyer.  #motivation #leadership #worry\nTokenised Tweet: â€œ-worry-is-a-down-payment-on-a-problem-you-may-never-have-'-.-joyce-meyer-.-#motivation-#leadership-#worry\n\nOriginal Tweet: My roommate: it's okay that we can't spell because we have autocorrect. #terrible #firstworldprobs\nTokenised Tweet: my-roommate-:-it-is-okay-that-we-cannot-spell-because-we-have-autocorrect-.-#terrible-#firstworldprobs\n\nOriginal Tweet: No but that's so cute. Atsu was probably shy about photos before but cherry helped her out uwu\nTokenised Tweet: no-but-that-is-so-cute-.-atsu-was-probably-shy-about-photos-before-but-cherry-helped-her-out-uwu\n\nOriginal Tweet: Rooneys fucking untouchable isn't he? Been fucking dreadful again, depay has looked decent(ish)tonight\nTokenised Tweet: rooneys-fucking-untouchable-is-not-he-?-been-fucking-dreadful-again-,-depay-has-looked-decent-(-ish-)-tonight\n\nOriginal Tweet: it's pretty depressing when u hit pan on ur favourite highlighter\nTokenised Tweet: it-is-pretty-depressing-when-you-hit-pan-on-ur-favourite-highlighter\n\nOriginal Tweet: @user but your pussy was weak from what I heard so stfu up to me bitch . You got to threaten him that your pregnant .\nTokenised Tweet: @user-but-your-pussy-was-weak-from-what-i-heard-so-stfu-up-to-me-bitch-.-you-got-to-threaten-him-that-your-pregnant-.\n\nOriginal Tweet: Making that yearly transition from excited and hopeful college returner to sick and exhausted pessimist. #college\nTokenised Tweet: making-that-yearly-transition-from-excited-and-hopeful-college-returner-to-sick-and-exhausted-pessimist-.-#college\n\nOriginal Tweet: Tiller and breezy should do a collab album. Rapping and singing prolly be fire\nTokenised Tweet: tiller-and-breezy-should-do-a-collab-album-.-rapping-and-singing-prolly-be-fire\n\nOriginal Tweet: @user broadband is shocking regretting signing up now #angry #shouldofgonewithvirgin\nTokenised Tweet: @user-broadband-is-shocking-regretting-signing-up-now-#angry-#shouldofgonewithvirgin\n\nOriginal Tweet: @user Look at those teef! #growl\nTokenised Tweet: @user-look-at-those-teef-!-#growl\n\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "In both small samples from the two datasets the tokeniser seems to perform well. As expected, we split the tweets by words. Furthermore, the tokeniser is able to keep hashtags, expand contractions, deal correctly with emojis and replace links with the dummy string.\nWe can now continue our work based on the tokenised data.",
   "metadata": {
    "tags": [],
    "cell_id": "00040-72d80d21-7124-4b56-945d-dc1d4d75819b",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "# Descriptive Statistics\n---\n*TASK 2* \n\nAn essential part of any NLP classfication task is to describe the corpus, so the entire tokenised data. In this section, we will step-by-step compute the most important statistics and visualise some of them for both datasets.",
   "metadata": {
    "cell_id": "00044-cef6a6e4-c220-496f-ada8-d6cfbc08f299",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Corpus\n---\nGenerally in linguistics, a corpus is a large and structured set of texts. The corpus is often used as the basis for a lot of descriptive analysis of the language data at hand. We therefore create a corpus for both training sets of our datasets using a flattened list, that is a linear conctentation of all tokens in the training sets of both datasets.",
   "metadata": {
    "tags": [],
    "cell_id": "00042-1e95836c-c9bd-4ece-9172-59d54d3e574e",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00046-c2b2e52f-155f-4bb0-82f8-3eb9d7f2c2c9",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "cac7dded",
    "execution_start": 1622701493483,
    "execution_millis": 19,
    "output_cleared": true,
    "deepnote_cell_type": "code"
   },
   "source": "# build entire corpus from training set in both datasets\nfor dataset in DATASETS:\n    CORPUS[dataset] = [token for tweet in DATA['processed'][dataset]['train_text'] for token in tweet]",
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00050-8a91ad41-e2f2-46cf-b897-ce337bbf738d",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "fad6c5f0",
    "execution_start": 1622701493502,
    "execution_millis": 14,
    "output_cleared": false,
    "deepnote_cell_type": "code"
   },
   "source": "for dataset in DATASETS:\n    print(f'Corpus Size ({dataset.title()}): {len(CORPUS[dataset])}')",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "text": "Corpus Size (Hate): 216076\nCorpus Size (Emotion): 60506\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "As we can see, the corpus for the `hate` classification is significantly larger with 216.076 total number of tokens than the `emotion` corpus with 60.506 tokens.",
   "metadata": {
    "tags": [],
    "cell_id": "00051-d506cc94-5179-4636-952a-85dbedfbf123",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Vocabulary \n---\nIn NLP, the set of unique words used in the text corpus is referred to as the vocabulary. The vocabulary is the basis for training machine learning models based on the bag-of-words approach, which treats every unique token as a feature in the classification.\n\nIn order to built the vocabulary, we use the `Counter` class from the `collections` standard library in python onto the corpus, in order to compute a dictionary containing all unique tokens (types) together with their corresponding frequency. We combine all data, together with some additional information like the `rank`, where 1 is the the most frequent token, the `normalised/ relative frequency` (frequency divided by total number of tokens) and the `cumulative frequency`. The final data frame will be sorted in descending order, from most to least frequent tokens.",
   "metadata": {
    "tags": [],
    "cell_id": "00044-839f89a7-e2e8-4f6b-b9b0-effc3f566bb3",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00042-f580c106-03ae-4ef2-a8de-3329cc7f39d7",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 33,
    "execution_start": 1622701493531,
    "output_cleared": true,
    "source_hash": "d2b04462",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "# build entire vocabulary from training tweets in both datasets\nfor dataset in DATASETS:\n    corpus = CORPUS[dataset]\n\n    # initialise frequency counter\n    VOCABULARY[dataset] = pd.DataFrame.from_dict(Counter(corpus), orient='index').reset_index().rename(columns={'index': 'token', 0: 'frequency'}).sort_values(by='frequency', ascending=False).reset_index().drop(columns=['index'])\n\n    VOCABULARY[dataset]['rank'] = VOCABULARY[dataset].index + 1 # add one to index to build rank\n    VOCABULARY[dataset]['normalised_frequency'] = VOCABULARY[dataset]['frequency'] / VOCABULARY[dataset]['frequency'].sum() # relative frequency\n    VOCABULARY[dataset]['cumulative_frequency'] = VOCABULARY[dataset]['normalised_frequency'].cumsum()",
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Let's have a look at the vocabulary dataframes constructed for both dataframes.",
   "metadata": {
    "tags": [],
    "cell_id": "00054-3ef36aa2-e3f2-404a-a526-c6c1a5e49a7c",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00046-5accac30-2f91-4cf6-8d65-ca5f6e2cfff1",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 74,
    "execution_start": 1622701493578,
    "output_cleared": false,
    "source_hash": "76d6d744",
    "tags": [],
    "deepnote_cell_type": "code"
   },
   "source": "VOCABULARY['hate']",
   "execution_count": 29,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 29,
     "data": {
      "application/vnd.deepnote.dataframe.v2+json": {
       "row_count": 18600,
       "column_count": 5,
       "columns": [
        {
         "name": "token",
         "dtype": "object",
         "stats": {
          "unique_count": 18600,
          "nan_count": 0,
          "categories": [
           {
            "name": ".",
            "count": 1
           },
           {
            "name": "@user",
            "count": 1
           },
           {
            "name": "18598 others",
            "count": 18598
           }
          ]
         }
        },
        {
         "name": "frequency",
         "dtype": "int64",
         "stats": {
          "unique_count": 294,
          "nan_count": 0,
          "min": "1",
          "max": "6277",
          "histogram": [
           {
            "bin_start": 1,
            "bin_end": 628.6,
            "count": 18551
           },
           {
            "bin_start": 628.6,
            "bin_end": 1256.2,
            "count": 30
           },
           {
            "bin_start": 1256.2,
            "bin_end": 1883.8000000000002,
            "count": 5
           },
           {
            "bin_start": 1883.8000000000002,
            "bin_end": 2511.4,
            "count": 3
           },
           {
            "bin_start": 2511.4,
            "bin_end": 3139,
            "count": 3
           },
           {
            "bin_start": 3139,
            "bin_end": 3766.6000000000004,
            "count": 1
           },
           {
            "bin_start": 3766.6000000000004,
            "bin_end": 4394.2,
            "count": 3
           },
           {
            "bin_start": 4394.2,
            "bin_end": 5021.8,
            "count": 1
           },
           {
            "bin_start": 5021.8,
            "bin_end": 5649.400000000001,
            "count": 1
           },
           {
            "bin_start": 5649.400000000001,
            "bin_end": 6277,
            "count": 2
           }
          ]
         }
        },
        {
         "name": "rank",
         "dtype": "int64",
         "stats": {
          "unique_count": 18600,
          "nan_count": 0,
          "min": "1",
          "max": "18600",
          "histogram": [
           {
            "bin_start": 1,
            "bin_end": 1860.9,
            "count": 1860
           },
           {
            "bin_start": 1860.9,
            "bin_end": 3720.8,
            "count": 1860
           },
           {
            "bin_start": 3720.8,
            "bin_end": 5580.700000000001,
            "count": 1860
           },
           {
            "bin_start": 5580.700000000001,
            "bin_end": 7440.6,
            "count": 1860
           },
           {
            "bin_start": 7440.6,
            "bin_end": 9300.5,
            "count": 1860
           },
           {
            "bin_start": 9300.5,
            "bin_end": 11160.400000000001,
            "count": 1860
           },
           {
            "bin_start": 11160.400000000001,
            "bin_end": 13020.300000000001,
            "count": 1860
           },
           {
            "bin_start": 13020.300000000001,
            "bin_end": 14880.2,
            "count": 1860
           },
           {
            "bin_start": 14880.2,
            "bin_end": 16740.100000000002,
            "count": 1860
           },
           {
            "bin_start": 16740.100000000002,
            "bin_end": 18600,
            "count": 1860
           }
          ]
         }
        },
        {
         "name": "normalised_frequency",
         "dtype": "float64",
         "stats": {
          "unique_count": 294,
          "nan_count": 0,
          "min": "4.628001258816342e-06",
          "max": "0.029049963901590183",
          "histogram": [
           {
            "bin_start": 0.000004628001258816342,
            "bin_end": 0.0029091615912919533,
            "count": 18551
           },
           {
            "bin_start": 0.0029091615912919533,
            "bin_end": 0.00581369518132509,
            "count": 30
           },
           {
            "bin_start": 0.00581369518132509,
            "bin_end": 0.008718228771358225,
            "count": 5
           },
           {
            "bin_start": 0.008718228771358225,
            "bin_end": 0.011622762361391363,
            "count": 3
           },
           {
            "bin_start": 0.011622762361391363,
            "bin_end": 0.0145272959514245,
            "count": 3
           },
           {
            "bin_start": 0.0145272959514245,
            "bin_end": 0.017431829541457635,
            "count": 1
           },
           {
            "bin_start": 0.017431829541457635,
            "bin_end": 0.020336363131490773,
            "count": 3
           },
           {
            "bin_start": 0.020336363131490773,
            "bin_end": 0.02324089672152391,
            "count": 1
           },
           {
            "bin_start": 0.02324089672152391,
            "bin_end": 0.02614543031155705,
            "count": 1
           },
           {
            "bin_start": 0.02614543031155705,
            "bin_end": 0.029049963901590183,
            "count": 2
           }
          ]
         }
        },
        {
         "name": "cumulative_frequency",
         "dtype": "float64",
         "stats": {
          "unique_count": 18600,
          "nan_count": 0,
          "min": "0.029049963901590183",
          "max": "0.9999999999996355",
          "histogram": [
           {
            "bin_start": 0.029049963901590183,
            "bin_end": 0.1261449675113947,
            "count": 5
           },
           {
            "bin_start": 0.1261449675113947,
            "bin_end": 0.22323997112119923,
            "count": 6
           },
           {
            "bin_start": 0.22323997112119923,
            "bin_end": 0.3203349747310038,
            "count": 15
           },
           {
            "bin_start": 0.3203349747310038,
            "bin_end": 0.4174299783408083,
            "count": 28
           },
           {
            "bin_start": 0.4174299783408083,
            "bin_end": 0.5145249819506128,
            "count": 48
           },
           {
            "bin_start": 0.5145249819506128,
            "bin_end": 0.6116199855604174,
            "count": 104
           },
           {
            "bin_start": 0.6116199855604174,
            "bin_end": 0.7087149891702219,
            "count": 276
           },
           {
            "bin_start": 0.7087149891702219,
            "bin_end": 0.8058099927800264,
            "count": 775
           },
           {
            "bin_start": 0.8058099927800264,
            "bin_end": 0.9029049963898309,
            "count": 2673
           },
           {
            "bin_start": 0.9029049963898309,
            "bin_end": 0.9999999999996355,
            "count": 14670
           }
          ]
         }
        },
        {
         "name": "_deepnote_index_column",
         "dtype": "int64"
        }
       ],
       "rows_top": [
        {
         "token": ".",
         "frequency": 6277,
         "rank": 1,
         "normalised_frequency": 0.029049963901590183,
         "cumulative_frequency": 0.029049963901590183,
         "_deepnote_index_column": 0
        },
        {
         "token": "@user",
         "frequency": 6014,
         "rank": 2,
         "normalised_frequency": 0.027832799570521483,
         "cumulative_frequency": 0.056882763472111665,
         "_deepnote_index_column": 1
        },
        {
         "token": "the",
         "frequency": 5492,
         "rank": 3,
         "normalised_frequency": 0.02541698291341935,
         "cumulative_frequency": 0.08229974638553102,
         "_deepnote_index_column": 2
        },
        {
         "token": "to",
         "frequency": 4931,
         "rank": 4,
         "normalised_frequency": 0.022820674207223383,
         "cumulative_frequency": 0.1051204205927544,
         "_deepnote_index_column": 3
        },
        {
         "token": ",",
         "frequency": 4356,
         "rank": 5,
         "normalised_frequency": 0.020159573483403987,
         "cumulative_frequency": 0.1252799940761584,
         "_deepnote_index_column": 4
        },
        {
         "token": "you",
         "frequency": 4106,
         "rank": 6,
         "normalised_frequency": 0.019002573168699903,
         "cumulative_frequency": 0.1442825672448583,
         "_deepnote_index_column": 5
        },
        {
         "token": "a",
         "frequency": 3953,
         "rank": 7,
         "normalised_frequency": 0.018294488976101003,
         "cumulative_frequency": 0.1625770562209593,
         "_deepnote_index_column": 6
        },
        {
         "token": "and",
         "frequency": 3221,
         "rank": 8,
         "normalised_frequency": 0.01490679205464744,
         "cumulative_frequency": 0.17748384827560673,
         "_deepnote_index_column": 7
        },
        {
         "token": "of",
         "frequency": 2886,
         "rank": 9,
         "normalised_frequency": 0.013356411632943965,
         "cumulative_frequency": 0.1908402599085507,
         "_deepnote_index_column": 8
        },
        {
         "token": "is",
         "frequency": 2719,
         "rank": 10,
         "normalised_frequency": 0.012583535422721635,
         "cumulative_frequency": 0.20342379533127233,
         "_deepnote_index_column": 9
        },
        {
         "token": "in",
         "frequency": 2562,
         "rank": 11,
         "normalised_frequency": 0.01185693922508747,
         "cumulative_frequency": 0.2152807345563598,
         "_deepnote_index_column": 10
        },
        {
         "token": "not",
         "frequency": 2402,
         "rank": 12,
         "normalised_frequency": 0.011116459023676854,
         "cumulative_frequency": 0.22639719358003665,
         "_deepnote_index_column": 11
        },
        {
         "token": "!",
         "frequency": 2147,
         "rank": 13,
         "normalised_frequency": 0.009936318702678687,
         "cumulative_frequency": 0.23633351228271535,
         "_deepnote_index_column": 12
        },
        {
         "token": "are",
         "frequency": 2056,
         "rank": 14,
         "normalised_frequency": 0.0095151705881264,
         "cumulative_frequency": 0.24584868287084174,
         "_deepnote_index_column": 13
        },
        {
         "token": "for",
         "frequency": 1828,
         "rank": 15,
         "normalised_frequency": 0.008459986301116273,
         "cumulative_frequency": 0.25430866917195805,
         "_deepnote_index_column": 14
        },
        {
         "token": "i",
         "frequency": 1792,
         "rank": 16,
         "normalised_frequency": 0.008293378255798886,
         "cumulative_frequency": 0.26260204742775695,
         "_deepnote_index_column": 15
        },
        {
         "token": "that",
         "frequency": 1531,
         "rank": 17,
         "normalised_frequency": 0.00708546992724782,
         "cumulative_frequency": 0.2696875173550048,
         "_deepnote_index_column": 16
        },
        {
         "token": "it",
         "frequency": 1359,
         "rank": 18,
         "normalised_frequency": 0.006289453710731409,
         "cumulative_frequency": 0.2759769710657362,
         "_deepnote_index_column": 17
        },
        {
         "token": "?",
         "frequency": 1353,
         "rank": 19,
         "normalised_frequency": 0.006261685703178511,
         "cumulative_frequency": 0.28223865676891474,
         "_deepnote_index_column": 18
        },
        {
         "token": "'",
         "frequency": 1244,
         "rank": 20,
         "normalised_frequency": 0.00575723356596753,
         "cumulative_frequency": 0.28799589033488227,
         "_deepnote_index_column": 19
        },
        {
         "token": "on",
         "frequency": 1183,
         "rank": 21,
         "normalised_frequency": 0.0054749254891797335,
         "cumulative_frequency": 0.293470815824062,
         "_deepnote_index_column": 20
        },
        {
         "token": "they",
         "frequency": 1073,
         "rank": 22,
         "normalised_frequency": 0.004965845350709935,
         "cumulative_frequency": 0.2984366611747719,
         "_deepnote_index_column": 21
        },
        {
         "token": "bitch",
         "frequency": 1069,
         "rank": 23,
         "normalised_frequency": 0.00494733334567467,
         "cumulative_frequency": 0.30338399452044656,
         "_deepnote_index_column": 22
        },
        {
         "token": "all",
         "frequency": 1061,
         "rank": 24,
         "normalised_frequency": 0.004910309335604139,
         "cumulative_frequency": 0.3082943038560507,
         "_deepnote_index_column": 23
        },
        {
         "token": "this",
         "frequency": 1044,
         "rank": 25,
         "normalised_frequency": 0.004831633314204262,
         "cumulative_frequency": 0.313125937170255,
         "_deepnote_index_column": 24
        },
        {
         "token": "do",
         "frequency": 1032,
         "rank": 26,
         "normalised_frequency": 0.004776097299098466,
         "cumulative_frequency": 0.31790203446935345,
         "_deepnote_index_column": 25
        },
        {
         "token": "have",
         "frequency": 1030,
         "rank": 27,
         "normalised_frequency": 0.004766841296580833,
         "cumulative_frequency": 0.3226688757659343,
         "_deepnote_index_column": 26
        },
        {
         "token": "your",
         "frequency": 970,
         "rank": 28,
         "normalised_frequency": 0.004489161221051852,
         "cumulative_frequency": 0.32715803698698614,
         "_deepnote_index_column": 27
        },
        {
         "token": "â€™",
         "frequency": 966,
         "rank": 29,
         "normalised_frequency": 0.004470649216016587,
         "cumulative_frequency": 0.33162868620300273,
         "_deepnote_index_column": 28
        },
        {
         "token": "-",
         "frequency": 943,
         "rank": 30,
         "normalised_frequency": 0.004364205187063811,
         "cumulative_frequency": 0.33599289139006655,
         "_deepnote_index_column": 29
        },
        {
         "token": "be",
         "frequency": 942,
         "rank": 31,
         "normalised_frequency": 0.0043595771858049946,
         "cumulative_frequency": 0.34035246857587154,
         "_deepnote_index_column": 30
        },
        {
         "token": "with",
         "frequency": 942,
         "rank": 32,
         "normalised_frequency": 0.0043595771858049946,
         "cumulative_frequency": 0.3447120457616765,
         "_deepnote_index_column": 31
        },
        {
         "token": "...",
         "frequency": 873,
         "rank": 33,
         "normalised_frequency": 0.004040245098946667,
         "cumulative_frequency": 0.3487522908606232,
         "_deepnote_index_column": 32
        },
        {
         "token": "women",
         "frequency": 840,
         "rank": 34,
         "normalised_frequency": 0.0038875210574057274,
         "cumulative_frequency": 0.35263981191802896,
         "_deepnote_index_column": 33
        },
        {
         "token": "we",
         "frequency": 837,
         "rank": 35,
         "normalised_frequency": 0.0038736370536292786,
         "cumulative_frequency": 0.3565134489716582,
         "_deepnote_index_column": 34
        },
        {
         "token": ":",
         "frequency": 833,
         "rank": 36,
         "normalised_frequency": 0.0038551250485940134,
         "cumulative_frequency": 0.36036857402025224,
         "_deepnote_index_column": 35
        },
        {
         "token": "refugees",
         "frequency": 819,
         "rank": 37,
         "normalised_frequency": 0.0037903330309705845,
         "cumulative_frequency": 0.36415890705122284,
         "_deepnote_index_column": 36
        },
        {
         "token": "will",
         "frequency": 745,
         "rank": 38,
         "normalised_frequency": 0.003447860937818175,
         "cumulative_frequency": 0.367606767989041,
         "_deepnote_index_column": 37
        },
        {
         "token": "\"",
         "frequency": 731,
         "rank": 39,
         "normalised_frequency": 0.0033830689201947463,
         "cumulative_frequency": 0.37098983690923576,
         "_deepnote_index_column": 38
        },
        {
         "token": "me",
         "frequency": 720,
         "rank": 40,
         "normalised_frequency": 0.0033321609063477666,
         "cumulative_frequency": 0.3743219978155835,
         "_deepnote_index_column": 39
        },
        {
         "token": "from",
         "frequency": 712,
         "rank": 41,
         "normalised_frequency": 0.0032951368962772357,
         "cumulative_frequency": 0.37761713471186076,
         "_deepnote_index_column": 40
        },
        {
         "token": "when",
         "frequency": 708,
         "rank": 42,
         "normalised_frequency": 0.0032766248912419705,
         "cumulative_frequency": 0.38089375960310273,
         "_deepnote_index_column": 41
        },
        {
         "token": "my",
         "frequency": 702,
         "rank": 43,
         "normalised_frequency": 0.0032488568836890725,
         "cumulative_frequency": 0.3841426164867918,
         "_deepnote_index_column": 42
        },
        {
         "token": "who",
         "frequency": 682,
         "rank": 44,
         "normalised_frequency": 0.0031562968585127455,
         "cumulative_frequency": 0.3872989133453046,
         "_deepnote_index_column": 43
        },
        {
         "token": "like",
         "frequency": 679,
         "rank": 45,
         "normalised_frequency": 0.0031424128547362963,
         "cumulative_frequency": 0.3904413262000409,
         "_deepnote_index_column": 44
        },
        {
         "token": "if",
         "frequency": 673,
         "rank": 46,
         "normalised_frequency": 0.0031146448471833983,
         "cumulative_frequency": 0.3935559710472243,
         "_deepnote_index_column": 45
        },
        {
         "token": "&",
         "frequency": 673,
         "rank": 47,
         "normalised_frequency": 0.0031146448471833983,
         "cumulative_frequency": 0.39667061589440766,
         "_deepnote_index_column": 46
        },
        {
         "token": "immigrant",
         "frequency": 654,
         "rank": 48,
         "normalised_frequency": 0.0030267128232658877,
         "cumulative_frequency": 0.39969732871767355,
         "_deepnote_index_column": 47
        },
        {
         "token": "but",
         "frequency": 630,
         "rank": 49,
         "normalised_frequency": 0.0029156407930542956,
         "cumulative_frequency": 0.40261296951072784,
         "_deepnote_index_column": 48
        },
        {
         "token": "their",
         "frequency": 625,
         "rank": 50,
         "normalised_frequency": 0.002892500786760214,
         "cumulative_frequency": 0.40550547029748807,
         "_deepnote_index_column": 49
        },
        {
         "token": "about",
         "frequency": 607,
         "rank": 51,
         "normalised_frequency": 0.00280919676410152,
         "cumulative_frequency": 0.4083146670615896,
         "_deepnote_index_column": 50
        },
        {
         "token": "no",
         "frequency": 600,
         "rank": 52,
         "normalised_frequency": 0.0027768007552898054,
         "cumulative_frequency": 0.4110914678168794,
         "_deepnote_index_column": 51
        },
        {
         "token": "s",
         "frequency": 583,
         "rank": 53,
         "normalised_frequency": 0.0026981247338899277,
         "cumulative_frequency": 0.4137895925507693,
         "_deepnote_index_column": 52
        },
        {
         "token": "as",
         "frequency": 582,
         "rank": 54,
         "normalised_frequency": 0.0026934967326311112,
         "cumulative_frequency": 0.4164830892834004,
         "_deepnote_index_column": 53
        },
        {
         "token": "so",
         "frequency": 580,
         "rank": 55,
         "normalised_frequency": 0.0026842407301134784,
         "cumulative_frequency": 0.41916733001351386,
         "_deepnote_index_column": 54
        },
        {
         "token": "by",
         "frequency": 578,
         "rank": 56,
         "normalised_frequency": 0.002674984727595846,
         "cumulative_frequency": 0.4218423147411097,
         "_deepnote_index_column": 55
        },
        {
         "token": "illegal",
         "frequency": 572,
         "rank": 57,
         "normalised_frequency": 0.002647216720042948,
         "cumulative_frequency": 0.42448953146115265,
         "_deepnote_index_column": 56
        },
        {
         "token": "up",
         "frequency": 569,
         "rank": 58,
         "normalised_frequency": 0.0026333327162664988,
         "cumulative_frequency": 0.4271228641774191,
         "_deepnote_index_column": 57
        },
        {
         "token": "what",
         "frequency": 554,
         "rank": 59,
         "normalised_frequency": 0.002563912697384254,
         "cumulative_frequency": 0.4296867768748034,
         "_deepnote_index_column": 58
        },
        {
         "token": "at",
         "frequency": 553,
         "rank": 60,
         "normalised_frequency": 0.0025592846961254375,
         "cumulative_frequency": 0.4322460615709288,
         "_deepnote_index_column": 59
        },
        {
         "token": "our",
         "frequency": 540,
         "rank": 61,
         "normalised_frequency": 0.002499120679760825,
         "cumulative_frequency": 0.43474518225068964,
         "_deepnote_index_column": 60
        },
        {
         "token": "just",
         "frequency": 531,
         "rank": 62,
         "normalised_frequency": 0.0024574686684314777,
         "cumulative_frequency": 0.43720265091912114,
         "_deepnote_index_column": 61
        },
        {
         "token": "or",
         "frequency": 519,
         "rank": 63,
         "normalised_frequency": 0.0024019326533256816,
         "cumulative_frequency": 0.4396045835724468,
         "_deepnote_index_column": 62
        },
        {
         "token": "immigration",
         "frequency": 516,
         "rank": 64,
         "normalised_frequency": 0.002388048649549233,
         "cumulative_frequency": 0.44199263222199603,
         "_deepnote_index_column": 63
        },
        {
         "token": "men",
         "frequency": 508,
         "rank": 65,
         "normalised_frequency": 0.002351024639478702,
         "cumulative_frequency": 0.44434365686147476,
         "_deepnote_index_column": 64
        },
        {
         "token": "get",
         "frequency": 501,
         "rank": 66,
         "normalised_frequency": 0.0023186286306669875,
         "cumulative_frequency": 0.44666228549214176,
         "_deepnote_index_column": 65
        },
        {
         "token": "people",
         "frequency": 498,
         "rank": 67,
         "normalised_frequency": 0.0023047446268905387,
         "cumulative_frequency": 0.44896703011903233,
         "_deepnote_index_column": 66
        },
        {
         "token": "migrants",
         "frequency": 495,
         "rank": 68,
         "normalised_frequency": 0.0022908606231140894,
         "cumulative_frequency": 0.4512578907421464,
         "_deepnote_index_column": 67
        },
        {
         "token": "them",
         "frequency": 490,
         "rank": 69,
         "normalised_frequency": 0.002267720616820008,
         "cumulative_frequency": 0.4535256113589664,
         "_deepnote_index_column": 68
        },
        {
         "token": "her",
         "frequency": 489,
         "rank": 70,
         "normalised_frequency": 0.0022630926155611914,
         "cumulative_frequency": 0.4557887039745276,
         "_deepnote_index_column": 69
        },
        {
         "token": "can",
         "frequency": 488,
         "rank": 71,
         "normalised_frequency": 0.002258464614302375,
         "cumulative_frequency": 0.45804716858883,
         "_deepnote_index_column": 70
        },
        {
         "token": "was",
         "frequency": 481,
         "rank": 72,
         "normalised_frequency": 0.0022260686054906605,
         "cumulative_frequency": 0.4602732371943207,
         "_deepnote_index_column": 71
        },
        {
         "token": "an",
         "frequency": 471,
         "rank": 73,
         "normalised_frequency": 0.0021797885929024973,
         "cumulative_frequency": 0.4624530257872232,
         "_deepnote_index_column": 72
        },
        {
         "token": "woman",
         "frequency": 465,
         "rank": 74,
         "normalised_frequency": 0.0021520205853495992,
         "cumulative_frequency": 0.46460504637257277,
         "_deepnote_index_column": 73
        },
        {
         "token": "cunt",
         "frequency": 454,
         "rank": 75,
         "normalised_frequency": 0.0021011125715026196,
         "cumulative_frequency": 0.4667061589440754,
         "_deepnote_index_column": 74
        },
        {
         "token": "rape",
         "frequency": 447,
         "rank": 76,
         "normalised_frequency": 0.002068716562690905,
         "cumulative_frequency": 0.46877487550676633,
         "_deepnote_index_column": 75
        },
        {
         "token": "how",
         "frequency": 444,
         "rank": 77,
         "normalised_frequency": 0.002054832558914456,
         "cumulative_frequency": 0.4708297080656808,
         "_deepnote_index_column": 76
        },
        {
         "token": "more",
         "frequency": 433,
         "rank": 78,
         "normalised_frequency": 0.002003924545067476,
         "cumulative_frequency": 0.4728336326107483,
         "_deepnote_index_column": 77
        },
        {
         "token": "want",
         "frequency": 432,
         "rank": 79,
         "normalised_frequency": 0.00199929654380866,
         "cumulative_frequency": 0.47483292915455694,
         "_deepnote_index_column": 78
        },
        {
         "token": "out",
         "frequency": 431,
         "rank": 80,
         "normalised_frequency": 0.0019946685425498434,
         "cumulative_frequency": 0.4768275976971068,
         "_deepnote_index_column": 79
        },
        {
         "token": "us",
         "frequency": 417,
         "rank": 81,
         "normalised_frequency": 0.0019298765249264147,
         "cumulative_frequency": 0.47875747422203324,
         "_deepnote_index_column": 80
        },
        {
         "token": "go",
         "frequency": 416,
         "rank": 82,
         "normalised_frequency": 0.0019252485236675985,
         "cumulative_frequency": 0.48068272274570084,
         "_deepnote_index_column": 81
        },
        {
         "token": "I",
         "frequency": 414,
         "rank": 83,
         "normalised_frequency": 0.0019159925211499657,
         "cumulative_frequency": 0.48259871526685083,
         "_deepnote_index_column": 82
        },
        {
         "token": "she",
         "frequency": 413,
         "rank": 84,
         "normalised_frequency": 0.0019113645198911495,
         "cumulative_frequency": 0.484510079786742,
         "_deepnote_index_column": 83
        },
        {
         "token": "he",
         "frequency": 404,
         "rank": 85,
         "normalised_frequency": 0.0018697125085618024,
         "cumulative_frequency": 0.4863797922953038,
         "_deepnote_index_column": 84
        },
        {
         "token": "am",
         "frequency": 397,
         "rank": 86,
         "normalised_frequency": 0.001837316499750088,
         "cumulative_frequency": 0.4882171087950539,
         "_deepnote_index_column": 85
        },
        {
         "token": "has",
         "frequency": 395,
         "rank": 87,
         "normalised_frequency": 0.0018280604972324554,
         "cumulative_frequency": 0.49004516929228636,
         "_deepnote_index_column": 86
        },
        {
         "token": "whore",
         "frequency": 393,
         "rank": 88,
         "normalised_frequency": 0.0018188044947148225,
         "cumulative_frequency": 0.4918639737870012,
         "_deepnote_index_column": 87
        },
        {
         "token": "#buildthatwall",
         "frequency": 371,
         "rank": 89,
         "normalised_frequency": 0.001716988467020863,
         "cumulative_frequency": 0.49358096225402204,
         "_deepnote_index_column": 88
        },
        {
         "token": "immigrants",
         "frequency": 364,
         "rank": 90,
         "normalised_frequency": 0.0016845924582091487,
         "cumulative_frequency": 0.49526555471223116,
         "_deepnote_index_column": 89
        },
        {
         "token": "one",
         "frequency": 360,
         "rank": 91,
         "normalised_frequency": 0.0016660804531738833,
         "cumulative_frequency": 0.49693163516540506,
         "_deepnote_index_column": 90
        },
        {
         "token": "fuck",
         "frequency": 354,
         "rank": 92,
         "normalised_frequency": 0.0016383124456209853,
         "cumulative_frequency": 0.498569947611026,
         "_deepnote_index_column": 91
        },
        {
         "token": "would",
         "frequency": 349,
         "rank": 93,
         "normalised_frequency": 0.0016151724393269034,
         "cumulative_frequency": 0.5001851200503529,
         "_deepnote_index_column": 92
        },
        {
         "token": "because",
         "frequency": 345,
         "rank": 94,
         "normalised_frequency": 0.0015966604342916382,
         "cumulative_frequency": 0.5017817804846445,
         "_deepnote_index_column": 93
        },
        {
         "token": "â€¦",
         "frequency": 344,
         "rank": 95,
         "normalised_frequency": 0.0015920324330328218,
         "cumulative_frequency": 0.5033738129176774,
         "_deepnote_index_column": 94
        },
        {
         "token": "why",
         "frequency": 338,
         "rank": 96,
         "normalised_frequency": 0.0015642644254799238,
         "cumulative_frequency": 0.5049380773431573,
         "_deepnote_index_column": 95
        },
        {
         "token": "time",
         "frequency": 337,
         "rank": 97,
         "normalised_frequency": 0.0015596364242211073,
         "cumulative_frequency": 0.5064977137673784,
         "_deepnote_index_column": 96
        },
        {
         "token": "should",
         "frequency": 332,
         "rank": 98,
         "normalised_frequency": 0.0015364964179270257,
         "cumulative_frequency": 0.5080342101853055,
         "_deepnote_index_column": 97
        },
        {
         "token": "now",
         "frequency": 326,
         "rank": 99,
         "normalised_frequency": 0.0015087284103741277,
         "cumulative_frequency": 0.5095429385956796,
         "_deepnote_index_column": 98
        },
        {
         "token": "know",
         "frequency": 316,
         "rank": 100,
         "normalised_frequency": 0.0014624483977859642,
         "cumulative_frequency": 0.5110053869934655,
         "_deepnote_index_column": 99
        }
       ],
       "rows_bottom": [
        {
         "token": "verses",
         "frequency": 1,
         "rank": 18501,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9995418278750166,
         "_deepnote_index_column": 18500
        },
        {
         "token": "fisherman",
         "frequency": 1,
         "rank": 18502,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9995464558762753,
         "_deepnote_index_column": 18501
        },
        {
         "token": "parent-child",
         "frequency": 1,
         "rank": 18503,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9995510838775341,
         "_deepnote_index_column": 18502
        },
        {
         "token": "retiring",
         "frequency": 1,
         "rank": 18504,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9995557118787929,
         "_deepnote_index_column": 18503
        },
        {
         "token": "heir",
         "frequency": 1,
         "rank": 18505,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9995603398800517,
         "_deepnote_index_column": 18504
        },
        {
         "token": "#sextraffickimg",
         "frequency": 1,
         "rank": 18506,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9995649678813104,
         "_deepnote_index_column": 18505
        },
        {
         "token": "#traffickstop",
         "frequency": 1,
         "rank": 18507,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9995695958825692,
         "_deepnote_index_column": 18506
        },
        {
         "token": "#bulldthewall",
         "frequency": 1,
         "rank": 18508,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.999574223883828,
         "_deepnote_index_column": 18507
        },
        {
         "token": "#endchainmigrationhere",
         "frequency": 1,
         "rank": 18509,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9995788518850868,
         "_deepnote_index_column": 18508
        },
        {
         "token": "molestation",
         "frequency": 1,
         "rank": 18510,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9995834798863455,
         "_deepnote_index_column": 18509
        },
        {
         "token": "employee",
         "frequency": 1,
         "rank": 18511,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9995881078876043,
         "_deepnote_index_column": 18510
        },
        {
         "token": "slipped",
         "frequency": 1,
         "rank": 18512,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9995927358888631,
         "_deepnote_index_column": 18511
        },
        {
         "token": "camouflaged",
         "frequency": 1,
         "rank": 18513,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9995973638901219,
         "_deepnote_index_column": 18512
        },
        {
         "token": "#8217",
         "frequency": 1,
         "rank": 18514,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9996019918913807,
         "_deepnote_index_column": 18513
        },
        {
         "token": "songbirds",
         "frequency": 1,
         "rank": 18515,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9996066198926394,
         "_deepnote_index_column": 18514
        },
        {
         "token": "overcoming",
         "frequency": 1,
         "rank": 18516,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9996112478938982,
         "_deepnote_index_column": 18515
        },
        {
         "token": "tumor",
         "frequency": 1,
         "rank": 18517,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.999615875895157,
         "_deepnote_index_column": 18516
        },
        {
         "token": "cras",
         "frequency": 1,
         "rank": 18518,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9996205038964158,
         "_deepnote_index_column": 18517
        },
        {
         "token": "imperil",
         "frequency": 1,
         "rank": 18519,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9996251318976745,
         "_deepnote_index_column": 18518
        },
        {
         "token": "waist",
         "frequency": 1,
         "rank": 18520,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9996297598989333,
         "_deepnote_index_column": 18519
        },
        {
         "token": "portions",
         "frequency": 1,
         "rank": 18521,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9996343879001921,
         "_deepnote_index_column": 18520
        },
        {
         "token": "capitalism",
         "frequency": 1,
         "rank": 18522,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9996390159014509,
         "_deepnote_index_column": 18521
        },
        {
         "token": "stressors",
         "frequency": 1,
         "rank": 18523,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9996436439027097,
         "_deepnote_index_column": 18522
        },
        {
         "token": "#brooklyn",
         "frequency": 1,
         "rank": 18524,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9996482719039684,
         "_deepnote_index_column": 18523
        },
        {
         "token": "#facesoffounders",
         "frequency": 1,
         "rank": 18525,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9996528999052272,
         "_deepnote_index_column": 18524
        },
        {
         "token": "handcuffed",
         "frequency": 1,
         "rank": 18526,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.999657527906486,
         "_deepnote_index_column": 18525
        },
        {
         "token": "solitary",
         "frequency": 1,
         "rank": 18527,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9996621559077448,
         "_deepnote_index_column": 18526
        },
        {
         "token": "confinement",
         "frequency": 1,
         "rank": 18528,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9996667839090035,
         "_deepnote_index_column": 18527
        },
        {
         "token": "shivering",
         "frequency": 1,
         "rank": 18529,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9996714119102623,
         "_deepnote_index_column": 18528
        },
        {
         "token": "#netneutrality",
         "frequency": 1,
         "rank": 18530,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9996760399115211,
         "_deepnote_index_column": 18529
        },
        {
         "token": "underneath",
         "frequency": 1,
         "rank": 18531,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9996806679127799,
         "_deepnote_index_column": 18530
        },
        {
         "token": "defaming",
         "frequency": 1,
         "rank": 18532,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9996852959140387,
         "_deepnote_index_column": 18531
        },
        {
         "token": "3103",
         "frequency": 1,
         "rank": 18533,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9996899239152974,
         "_deepnote_index_column": 18532
        },
        {
         "token": "scraps",
         "frequency": 1,
         "rank": 18534,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9996945519165562,
         "_deepnote_index_column": 18533
        },
        {
         "token": "#ent4all",
         "frequency": 1,
         "rank": 18535,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.999699179917815,
         "_deepnote_index_column": 18534
        },
        {
         "token": "3488",
         "frequency": 1,
         "rank": 18536,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9997038079190738,
         "_deepnote_index_column": 18535
        },
        {
         "token": "premier",
         "frequency": 1,
         "rank": 18537,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9997084359203325,
         "_deepnote_index_column": 18536
        },
        {
         "token": "sgut",
         "frequency": 1,
         "rank": 18538,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9997130639215913,
         "_deepnote_index_column": 18537
        },
        {
         "token": "uglyass",
         "frequency": 1,
         "rank": 18539,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9997176919228501,
         "_deepnote_index_column": 18538
        },
        {
         "token": "boyf",
         "frequency": 1,
         "rank": 18540,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9997223199241089,
         "_deepnote_index_column": 18539
        },
        {
         "token": "yu",
         "frequency": 1,
         "rank": 18541,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9997269479253676,
         "_deepnote_index_column": 18540
        },
        {
         "token": "shitshow",
         "frequency": 1,
         "rank": 18542,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9997315759266264,
         "_deepnote_index_column": 18541
        },
        {
         "token": "sung",
         "frequency": 1,
         "rank": 18543,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9997362039278852,
         "_deepnote_index_column": 18542
        },
        {
         "token": "intend",
         "frequency": 1,
         "rank": 18544,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.999740831929144,
         "_deepnote_index_column": 18543
        },
        {
         "token": "#russiagate",
         "frequency": 1,
         "rank": 18545,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9997454599304028,
         "_deepnote_index_column": 18544
        },
        {
         "token": "councillor",
         "frequency": 1,
         "rank": 18546,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9997500879316615,
         "_deepnote_index_column": 18545
        },
        {
         "token": "#femalefounders",
         "frequency": 1,
         "rank": 18547,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9997547159329203,
         "_deepnote_index_column": 18546
        },
        {
         "token": "giorgio",
         "frequency": 1,
         "rank": 18548,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9997593439341791,
         "_deepnote_index_column": 18547
        },
        {
         "token": "mammoliti",
         "frequency": 1,
         "rank": 18549,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9997639719354379,
         "_deepnote_index_column": 18548
        },
        {
         "token": "dawn",
         "frequency": 1,
         "rank": 18550,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9997685999366966,
         "_deepnote_index_column": 18549
        },
        {
         "token": "adam",
         "frequency": 1,
         "rank": 18551,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9997732279379554,
         "_deepnote_index_column": 18550
        },
        {
         "token": "vaughan",
         "frequency": 1,
         "rank": 18552,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9997778559392142,
         "_deepnote_index_column": 18551
        },
        {
         "token": "#tocouncil",
         "frequency": 1,
         "rank": 18553,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.999782483940473,
         "_deepnote_index_column": 18552
        },
        {
         "token": "#topoli",
         "frequency": 1,
         "rank": 18554,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9997871119417318,
         "_deepnote_index_column": 18553
        },
        {
         "token": "#voteoutthedems",
         "frequency": 1,
         "rank": 18555,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9997917399429905,
         "_deepnote_index_column": 18554
        },
        {
         "token": "3109",
         "frequency": 1,
         "rank": 18556,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9997963679442493,
         "_deepnote_index_column": 18555
        },
        {
         "token": "ay",
         "frequency": 1,
         "rank": 18557,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9998009959455081,
         "_deepnote_index_column": 18556
        },
        {
         "token": "ravaged",
         "frequency": 1,
         "rank": 18558,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9998056239467669,
         "_deepnote_index_column": 18557
        },
        {
         "token": "hobedi@wr.org",
         "frequency": 1,
         "rank": 18559,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9998102519480256,
         "_deepnote_index_column": 18558
        },
        {
         "token": "kuo's",
         "frequency": 1,
         "rank": 18560,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9998148799492844,
         "_deepnote_index_column": 18559
        },
        {
         "token": "writer",
         "frequency": 1,
         "rank": 18561,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9998195079505432,
         "_deepnote_index_column": 18560
        },
        {
         "token": "overcame",
         "frequency": 1,
         "rank": 18562,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.999824135951802,
         "_deepnote_index_column": 18561
        },
        {
         "token": "#asianamerican",
         "frequency": 1,
         "rank": 18563,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9998287639530608,
         "_deepnote_index_column": 18562
        },
        {
         "token": "#qwoc",
         "frequency": 1,
         "rank": 18564,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9998333919543195,
         "_deepnote_index_column": 18563
        },
        {
         "token": "#femalefilmmaker",
         "frequency": 1,
         "rank": 18565,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9998380199555783,
         "_deepnote_index_column": 18564
        },
        {
         "token": "#supportindiefilms",
         "frequency": 1,
         "rank": 18566,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9998426479568371,
         "_deepnote_index_column": 18565
        },
        {
         "token": "navigating",
         "frequency": 1,
         "rank": 18567,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9998472759580959,
         "_deepnote_index_column": 18566
        },
        {
         "token": "#guwop",
         "frequency": 1,
         "rank": 18568,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9998519039593546,
         "_deepnote_index_column": 18567
        },
        {
         "token": "becuz",
         "frequency": 1,
         "rank": 18569,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9998565319606134,
         "_deepnote_index_column": 18568
        },
        {
         "token": "gut-wrenching",
         "frequency": 1,
         "rank": 18570,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9998611599618722,
         "_deepnote_index_column": 18569
        },
        {
         "token": "sham",
         "frequency": 1,
         "rank": 18571,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.999865787963131,
         "_deepnote_index_column": 18570
        },
        {
         "token": "englan",
         "frequency": 1,
         "rank": 18572,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9998704159643897,
         "_deepnote_index_column": 18571
        },
        {
         "token": "2cthey",
         "frequency": 1,
         "rank": 18573,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9998750439656485,
         "_deepnote_index_column": 18572
        },
        {
         "token": "2gain",
         "frequency": 1,
         "rank": 18574,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9998796719669073,
         "_deepnote_index_column": 18573
        },
        {
         "token": "dialogues",
         "frequency": 1,
         "rank": 18575,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9998842999681661,
         "_deepnote_index_column": 18574
        },
        {
         "token": "harressment",
         "frequency": 1,
         "rank": 18576,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9998889279694249,
         "_deepnote_index_column": 18575
        },
        {
         "token": "bash",
         "frequency": 1,
         "rank": 18577,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9998935559706836,
         "_deepnote_index_column": 18576
        },
        {
         "token": "orgies",
         "frequency": 1,
         "rank": 18578,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9998981839719424,
         "_deepnote_index_column": 18577
        },
        {
         "token": "panny",
         "frequency": 1,
         "rank": 18579,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9999028119732012,
         "_deepnote_index_column": 18578
        },
        {
         "token": "sticking",
         "frequency": 1,
         "rank": 18580,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.99990743997446,
         "_deepnote_index_column": 18579
        },
        {
         "token": "commies",
         "frequency": 1,
         "rank": 18581,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9999120679757187,
         "_deepnote_index_column": 18580
        },
        {
         "token": "pests",
         "frequency": 1,
         "rank": 18582,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9999166959769775,
         "_deepnote_index_column": 18581
        },
        {
         "token": "snakes",
         "frequency": 1,
         "rank": 18583,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9999213239782363,
         "_deepnote_index_column": 18582
        },
        {
         "token": "vermin",
         "frequency": 1,
         "rank": 18584,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9999259519794951,
         "_deepnote_index_column": 18583
        },
        {
         "token": "#marr",
         "frequency": 1,
         "rank": 18585,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9999305799807539,
         "_deepnote_index_column": 18584
        },
        {
         "token": "presented",
         "frequency": 1,
         "rank": 18586,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9999352079820126,
         "_deepnote_index_column": 18585
        },
        {
         "token": "5-10",
         "frequency": 1,
         "rank": 18587,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9999398359832714,
         "_deepnote_index_column": 18586
        },
        {
         "token": "throes",
         "frequency": 1,
         "rank": 18588,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9999444639845302,
         "_deepnote_index_column": 18587
        },
        {
         "token": "louder",
         "frequency": 1,
         "rank": 18589,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.999949091985789,
         "_deepnote_index_column": 18588
        },
        {
         "token": "#howdoyoulikeusnow",
         "frequency": 1,
         "rank": 18590,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9999537199870477,
         "_deepnote_index_column": 18589
        },
        {
         "token": "#bloodycat",
         "frequency": 1,
         "rank": 18591,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9999583479883065,
         "_deepnote_index_column": 18590
        },
        {
         "token": "ðŸ¤•",
         "frequency": 1,
         "rank": 18592,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9999629759895653,
         "_deepnote_index_column": 18591
        },
        {
         "token": "photoshopped",
         "frequency": 1,
         "rank": 18593,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9999676039908241,
         "_deepnote_index_column": 18592
        },
        {
         "token": "badass",
         "frequency": 1,
         "rank": 18594,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9999722319920828,
         "_deepnote_index_column": 18593
        },
        {
         "token": "romansh",
         "frequency": 1,
         "rank": 18595,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9999768599933416,
         "_deepnote_index_column": 18594
        },
        {
         "token": "weren",
         "frequency": 1,
         "rank": 18596,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9999814879946004,
         "_deepnote_index_column": 18595
        },
        {
         "token": "miaow-miaow-miaow",
         "frequency": 1,
         "rank": 18597,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9999861159958592,
         "_deepnote_index_column": 18596
        },
        {
         "token": "aaaaw",
         "frequency": 1,
         "rank": 18598,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.999990743997118,
         "_deepnote_index_column": 18597
        },
        {
         "token": "food-hole",
         "frequency": 1,
         "rank": 18599,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9999953719983767,
         "_deepnote_index_column": 18598
        },
        {
         "token": "pic.why",
         "frequency": 1,
         "rank": 18600,
         "normalised_frequency": 0.000004628001258816342,
         "cumulative_frequency": 0.9999999999996355,
         "_deepnote_index_column": 18599
        }
       ]
      },
      "text/plain": "                   token  frequency   rank  normalised_frequency  \\\n0                      .       6277      1              0.029050   \n1                  @user       6014      2              0.027833   \n2                    the       5492      3              0.025417   \n3                     to       4931      4              0.022821   \n4                      ,       4356      5              0.020160   \n...                  ...        ...    ...                   ...   \n18595              weren          1  18596              0.000005   \n18596  miaow-miaow-miaow          1  18597              0.000005   \n18597              aaaaw          1  18598              0.000005   \n18598          food-hole          1  18599              0.000005   \n18599            pic.why          1  18600              0.000005   \n\n       cumulative_frequency  \n0                  0.029050  \n1                  0.056883  \n2                  0.082300  \n3                  0.105120  \n4                  0.125280  \n...                     ...  \n18595              0.999981  \n18596              0.999986  \n18597              0.999991  \n18598              0.999995  \n18599              1.000000  \n\n[18600 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>token</th>\n      <th>frequency</th>\n      <th>rank</th>\n      <th>normalised_frequency</th>\n      <th>cumulative_frequency</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>.</td>\n      <td>6277</td>\n      <td>1</td>\n      <td>0.029050</td>\n      <td>0.029050</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@user</td>\n      <td>6014</td>\n      <td>2</td>\n      <td>0.027833</td>\n      <td>0.056883</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>the</td>\n      <td>5492</td>\n      <td>3</td>\n      <td>0.025417</td>\n      <td>0.082300</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>to</td>\n      <td>4931</td>\n      <td>4</td>\n      <td>0.022821</td>\n      <td>0.105120</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>,</td>\n      <td>4356</td>\n      <td>5</td>\n      <td>0.020160</td>\n      <td>0.125280</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>18595</th>\n      <td>weren</td>\n      <td>1</td>\n      <td>18596</td>\n      <td>0.000005</td>\n      <td>0.999981</td>\n    </tr>\n    <tr>\n      <th>18596</th>\n      <td>miaow-miaow-miaow</td>\n      <td>1</td>\n      <td>18597</td>\n      <td>0.000005</td>\n      <td>0.999986</td>\n    </tr>\n    <tr>\n      <th>18597</th>\n      <td>aaaaw</td>\n      <td>1</td>\n      <td>18598</td>\n      <td>0.000005</td>\n      <td>0.999991</td>\n    </tr>\n    <tr>\n      <th>18598</th>\n      <td>food-hole</td>\n      <td>1</td>\n      <td>18599</td>\n      <td>0.000005</td>\n      <td>0.999995</td>\n    </tr>\n    <tr>\n      <th>18599</th>\n      <td>pic.why</td>\n      <td>1</td>\n      <td>18600</td>\n      <td>0.000005</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>18600 rows Ã— 5 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00055-e83734c0-8d5f-4ade-80c9-de9ab6ebe35e",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "81b7fded",
    "execution_start": 1622701493648,
    "execution_millis": 99,
    "output_cleared": false,
    "deepnote_cell_type": "code"
   },
   "source": "VOCABULARY['emotion']",
   "execution_count": 30,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 30,
     "data": {
      "application/vnd.deepnote.dataframe.v2+json": {
       "row_count": 9264,
       "column_count": 5,
       "columns": [
        {
         "name": "token",
         "dtype": "object",
         "stats": {
          "unique_count": 9264,
          "nan_count": 0,
          "categories": [
           {
            "name": "@user",
            "count": 1
           },
           {
            "name": ".",
            "count": 1
           },
           {
            "name": "9262 others",
            "count": 9262
           }
          ]
         }
        },
        {
         "name": "frequency",
         "dtype": "int64",
         "stats": {
          "unique_count": 153,
          "nan_count": 0,
          "min": "1",
          "max": "2019",
          "histogram": [
           {
            "bin_start": 1,
            "bin_end": 202.8,
            "count": 9225
           },
           {
            "bin_start": 202.8,
            "bin_end": 404.6,
            "count": 18
           },
           {
            "bin_start": 404.6,
            "bin_end": 606.4000000000001,
            "count": 7
           },
           {
            "bin_start": 606.4000000000001,
            "bin_end": 808.2,
            "count": 4
           },
           {
            "bin_start": 808.2,
            "bin_end": 1010,
            "count": 2
           },
           {
            "bin_start": 1010,
            "bin_end": 1211.8000000000002,
            "count": 4
           },
           {
            "bin_start": 1211.8000000000002,
            "bin_end": 1413.6000000000001,
            "count": 1
           },
           {
            "bin_start": 1413.6000000000001,
            "bin_end": 1615.4,
            "count": 1
           },
           {
            "bin_start": 1615.4,
            "bin_end": 1817.2,
            "count": 0
           },
           {
            "bin_start": 1817.2,
            "bin_end": 2019,
            "count": 2
           }
          ]
         }
        },
        {
         "name": "rank",
         "dtype": "int64",
         "stats": {
          "unique_count": 9264,
          "nan_count": 0,
          "min": "1",
          "max": "9264",
          "histogram": [
           {
            "bin_start": 1,
            "bin_end": 927.3,
            "count": 927
           },
           {
            "bin_start": 927.3,
            "bin_end": 1853.6,
            "count": 926
           },
           {
            "bin_start": 1853.6,
            "bin_end": 2779.8999999999996,
            "count": 926
           },
           {
            "bin_start": 2779.8999999999996,
            "bin_end": 3706.2,
            "count": 927
           },
           {
            "bin_start": 3706.2,
            "bin_end": 4632.5,
            "count": 926
           },
           {
            "bin_start": 4632.5,
            "bin_end": 5558.799999999999,
            "count": 926
           },
           {
            "bin_start": 5558.799999999999,
            "bin_end": 6485.099999999999,
            "count": 927
           },
           {
            "bin_start": 6485.099999999999,
            "bin_end": 7411.4,
            "count": 926
           },
           {
            "bin_start": 7411.4,
            "bin_end": 8337.699999999999,
            "count": 926
           },
           {
            "bin_start": 8337.699999999999,
            "bin_end": 9264,
            "count": 927
           }
          ]
         }
        },
        {
         "name": "normalised_frequency",
         "dtype": "float64",
         "stats": {
          "unique_count": 153,
          "nan_count": 0,
          "min": "1.6527286550094206e-05",
          "max": "0.033368591544640204",
          "histogram": [
           {
            "bin_start": 0.000016527286550094206,
            "bin_end": 0.0033517337123591053,
            "count": 9225
           },
           {
            "bin_start": 0.0033517337123591053,
            "bin_end": 0.006686940138168116,
            "count": 18
           },
           {
            "bin_start": 0.006686940138168116,
            "bin_end": 0.010022146563977128,
            "count": 7
           },
           {
            "bin_start": 0.010022146563977128,
            "bin_end": 0.01335735298978614,
            "count": 4
           },
           {
            "bin_start": 0.01335735298978614,
            "bin_end": 0.01669255941559515,
            "count": 2
           },
           {
            "bin_start": 0.01669255941559515,
            "bin_end": 0.02002776584140416,
            "count": 4
           },
           {
            "bin_start": 0.02002776584140416,
            "bin_end": 0.023362972267213174,
            "count": 1
           },
           {
            "bin_start": 0.023362972267213174,
            "bin_end": 0.026698178693022184,
            "count": 1
           },
           {
            "bin_start": 0.026698178693022184,
            "bin_end": 0.030033385118831194,
            "count": 0
           },
           {
            "bin_start": 0.030033385118831194,
            "bin_end": 0.033368591544640204,
            "count": 2
           }
          ]
         }
        },
        {
         "name": "cumulative_frequency",
         "dtype": "float64",
         "stats": {
          "unique_count": 9264,
          "nan_count": 0,
          "min": "0.033368591544640204",
          "max": "1.0000000000001081",
          "histogram": [
           {
            "bin_start": 0.033368591544640204,
            "bin_end": 0.130031732390187,
            "count": 4
           },
           {
            "bin_start": 0.130031732390187,
            "bin_end": 0.22669487323573378,
            "count": 7
           },
           {
            "bin_start": 0.22669487323573378,
            "bin_end": 0.3233580140812806,
            "count": 11
           },
           {
            "bin_start": 0.3233580140812806,
            "bin_end": 0.4200211549268274,
            "count": 22
           },
           {
            "bin_start": 0.4200211549268274,
            "bin_end": 0.5166842957723742,
            "count": 53
           },
           {
            "bin_start": 0.5166842957723742,
            "bin_end": 0.613347436617921,
            "count": 135
           },
           {
            "bin_start": 0.613347436617921,
            "bin_end": 0.7100105774634677,
            "count": 320
           },
           {
            "bin_start": 0.7100105774634677,
            "bin_end": 0.8066737183090146,
            "count": 818
           },
           {
            "bin_start": 0.8066737183090146,
            "bin_end": 0.9033368591545614,
            "count": 2290
           },
           {
            "bin_start": 0.9033368591545614,
            "bin_end": 1.0000000000001081,
            "count": 5604
           }
          ]
         }
        },
        {
         "name": "_deepnote_index_column",
         "dtype": "int64"
        }
       ],
       "rows_top": [
        {
         "token": "@user",
         "frequency": 2019,
         "rank": 1,
         "normalised_frequency": 0.033368591544640204,
         "cumulative_frequency": 0.033368591544640204,
         "_deepnote_index_column": 0
        },
        {
         "token": ".",
         "frequency": 1977,
         "rank": 2,
         "normalised_frequency": 0.03267444550953624,
         "cumulative_frequency": 0.06604303705417644,
         "_deepnote_index_column": 1
        },
        {
         "token": "the",
         "frequency": 1519,
         "rank": 3,
         "normalised_frequency": 0.0251049482695931,
         "cumulative_frequency": 0.09114798532376954,
         "_deepnote_index_column": 2
        },
        {
         "token": "to",
         "frequency": 1258,
         "rank": 4,
         "normalised_frequency": 0.02079132648001851,
         "cumulative_frequency": 0.11193931180378805,
         "_deepnote_index_column": 3
        },
        {
         "token": "i",
         "frequency": 1177,
         "rank": 5,
         "normalised_frequency": 0.01945261626946088,
         "cumulative_frequency": 0.13139192807324893,
         "_deepnote_index_column": 4
        },
        {
         "token": "is",
         "frequency": 1095,
         "rank": 6,
         "normalised_frequency": 0.018097378772353154,
         "cumulative_frequency": 0.14948930684560208,
         "_deepnote_index_column": 5
        },
        {
         "token": ",",
         "frequency": 1089,
         "rank": 7,
         "normalised_frequency": 0.01799821505305259,
         "cumulative_frequency": 0.16748752189865468,
         "_deepnote_index_column": 6
        },
        {
         "token": "a",
         "frequency": 1055,
         "rank": 8,
         "normalised_frequency": 0.017436287310349387,
         "cumulative_frequency": 0.18492380920900406,
         "_deepnote_index_column": 7
        },
        {
         "token": "and",
         "frequency": 888,
         "rank": 9,
         "normalised_frequency": 0.014676230456483655,
         "cumulative_frequency": 0.19960003966548773,
         "_deepnote_index_column": 8
        },
        {
         "token": "you",
         "frequency": 835,
         "rank": 10,
         "normalised_frequency": 0.013800284269328661,
         "cumulative_frequency": 0.2134003239348164,
         "_deepnote_index_column": 9
        },
        {
         "token": "!",
         "frequency": 762,
         "rank": 11,
         "normalised_frequency": 0.012593792351171784,
         "cumulative_frequency": 0.22599411628598817,
         "_deepnote_index_column": 10
        },
        {
         "token": "not",
         "frequency": 700,
         "rank": 12,
         "normalised_frequency": 0.011569100585065944,
         "cumulative_frequency": 0.2375632168710541,
         "_deepnote_index_column": 11
        },
        {
         "token": "of",
         "frequency": 686,
         "rank": 13,
         "normalised_frequency": 0.011337718573364625,
         "cumulative_frequency": 0.24890093544441874,
         "_deepnote_index_column": 12
        },
        {
         "token": "it",
         "frequency": 645,
         "rank": 14,
         "normalised_frequency": 0.010660099824810762,
         "cumulative_frequency": 0.2595610352692295,
         "_deepnote_index_column": 13
        },
        {
         "token": "in",
         "frequency": 567,
         "rank": 15,
         "normalised_frequency": 0.009370971473903415,
         "cumulative_frequency": 0.26893200674313295,
         "_deepnote_index_column": 14
        },
        {
         "token": "that",
         "frequency": 529,
         "rank": 16,
         "normalised_frequency": 0.008742934584999834,
         "cumulative_frequency": 0.27767494132813275,
         "_deepnote_index_column": 15
        },
        {
         "token": "my",
         "frequency": 497,
         "rank": 17,
         "normalised_frequency": 0.00821406141539682,
         "cumulative_frequency": 0.2858890027435296,
         "_deepnote_index_column": 16
        },
        {
         "token": "?",
         "frequency": 429,
         "rank": 18,
         "normalised_frequency": 0.007090205929990414,
         "cumulative_frequency": 0.29297920867352,
         "_deepnote_index_column": 17
        },
        {
         "token": "for",
         "frequency": 417,
         "rank": 19,
         "normalised_frequency": 0.006891878491389284,
         "cumulative_frequency": 0.2998710871649093,
         "_deepnote_index_column": 18
        },
        {
         "token": "'",
         "frequency": 416,
         "rank": 20,
         "normalised_frequency": 0.00687535120483919,
         "cumulative_frequency": 0.30674643836974846,
         "_deepnote_index_column": 19
        },
        {
         "token": "I",
         "frequency": 411,
         "rank": 21,
         "normalised_frequency": 0.0067927147720887185,
         "cumulative_frequency": 0.31353915314183717,
         "_deepnote_index_column": 20
        },
        {
         "token": "am",
         "frequency": 382,
         "rank": 22,
         "normalised_frequency": 0.006313423462135987,
         "cumulative_frequency": 0.31985257660397315,
         "_deepnote_index_column": 21
        },
        {
         "token": "on",
         "frequency": 379,
         "rank": 23,
         "normalised_frequency": 0.006263841602485704,
         "cumulative_frequency": 0.32611641820645887,
         "_deepnote_index_column": 22
        },
        {
         "token": "have",
         "frequency": 372,
         "rank": 24,
         "normalised_frequency": 0.006148150596635044,
         "cumulative_frequency": 0.3322645688030939,
         "_deepnote_index_column": 23
        },
        {
         "token": "do",
         "frequency": 363,
         "rank": 25,
         "normalised_frequency": 0.005999405017684196,
         "cumulative_frequency": 0.3382639738207781,
         "_deepnote_index_column": 24
        },
        {
         "token": "me",
         "frequency": 356,
         "rank": 26,
         "normalised_frequency": 0.005883714011833538,
         "cumulative_frequency": 0.3441476878326116,
         "_deepnote_index_column": 25
        },
        {
         "token": "are",
         "frequency": 330,
         "rank": 27,
         "normalised_frequency": 0.005454004561531087,
         "cumulative_frequency": 0.34960169239414274,
         "_deepnote_index_column": 26
        },
        {
         "token": "so",
         "frequency": 298,
         "rank": 28,
         "normalised_frequency": 0.0049251313919280735,
         "cumulative_frequency": 0.3545268237860708,
         "_deepnote_index_column": 27
        },
        {
         "token": "this",
         "frequency": 298,
         "rank": 29,
         "normalised_frequency": 0.0049251313919280735,
         "cumulative_frequency": 0.3594519551779989,
         "_deepnote_index_column": 28
        },
        {
         "token": "with",
         "frequency": 296,
         "rank": 30,
         "normalised_frequency": 0.004892076818827885,
         "cumulative_frequency": 0.36434403199682674,
         "_deepnote_index_column": 29
        },
        {
         "token": "just",
         "frequency": 280,
         "rank": 31,
         "normalised_frequency": 0.004627640234026378,
         "cumulative_frequency": 0.36897167223085314,
         "_deepnote_index_column": 30
        },
        {
         "token": "be",
         "frequency": 269,
         "rank": 32,
         "normalised_frequency": 0.004445840081975341,
         "cumulative_frequency": 0.3734175123128285,
         "_deepnote_index_column": 31
        },
        {
         "token": "...",
         "frequency": 266,
         "rank": 33,
         "normalised_frequency": 0.004396258222325059,
         "cumulative_frequency": 0.3778137705351535,
         "_deepnote_index_column": 32
        },
        {
         "token": "but",
         "frequency": 265,
         "rank": 34,
         "normalised_frequency": 0.0043797309357749645,
         "cumulative_frequency": 0.3821935014709285,
         "_deepnote_index_column": 33
        },
        {
         "token": "at",
         "frequency": 245,
         "rank": 35,
         "normalised_frequency": 0.004049185204773081,
         "cumulative_frequency": 0.3862426866757016,
         "_deepnote_index_column": 34
        },
        {
         "token": "was",
         "frequency": 242,
         "rank": 36,
         "normalised_frequency": 0.0039996033451227975,
         "cumulative_frequency": 0.3902422900208244,
         "_deepnote_index_column": 35
        },
        {
         "token": "your",
         "frequency": 233,
         "rank": 37,
         "normalised_frequency": 0.0038508577661719497,
         "cumulative_frequency": 0.39409314778699633,
         "_deepnote_index_column": 36
        },
        {
         "token": "like",
         "frequency": 226,
         "rank": 38,
         "normalised_frequency": 0.0037351667603212906,
         "cumulative_frequency": 0.39782831454731765,
         "_deepnote_index_column": 37
        },
        {
         "token": "all",
         "frequency": 210,
         "rank": 39,
         "normalised_frequency": 0.003470730175519783,
         "cumulative_frequency": 0.40129904472283745,
         "_deepnote_index_column": 38
        },
        {
         "token": "when",
         "frequency": 198,
         "rank": 40,
         "normalised_frequency": 0.0032724027369186526,
         "cumulative_frequency": 0.4045714474597561,
         "_deepnote_index_column": 39
        },
        {
         "token": "will",
         "frequency": 194,
         "rank": 41,
         "normalised_frequency": 0.0032062935907182758,
         "cumulative_frequency": 0.4077777410504744,
         "_deepnote_index_column": 40
        },
        {
         "token": "if",
         "frequency": 193,
         "rank": 42,
         "normalised_frequency": 0.0031897663041681817,
         "cumulative_frequency": 0.41096750735464255,
         "_deepnote_index_column": 41
        },
        {
         "token": "he",
         "frequency": 192,
         "rank": 43,
         "normalised_frequency": 0.0031732390176180876,
         "cumulative_frequency": 0.4141407463722606,
         "_deepnote_index_column": 42
        },
        {
         "token": "-",
         "frequency": 190,
         "rank": 44,
         "normalised_frequency": 0.003140184444517899,
         "cumulative_frequency": 0.41728093081677853,
         "_deepnote_index_column": 43
        },
        {
         "token": "what",
         "frequency": 188,
         "rank": 45,
         "normalised_frequency": 0.0031071298714177107,
         "cumulative_frequency": 0.42038806068819623,
         "_deepnote_index_column": 44
        },
        {
         "token": "they",
         "frequency": 179,
         "rank": 46,
         "normalised_frequency": 0.002958384292466863,
         "cumulative_frequency": 0.4233464449806631,
         "_deepnote_index_column": 45
        },
        {
         "token": "about",
         "frequency": 173,
         "rank": 47,
         "normalised_frequency": 0.0028592205731662974,
         "cumulative_frequency": 0.4262056655538294,
         "_deepnote_index_column": 46
        },
        {
         "token": "out",
         "frequency": 170,
         "rank": 48,
         "normalised_frequency": 0.002809638713516015,
         "cumulative_frequency": 0.4290153042673454,
         "_deepnote_index_column": 47
        },
        {
         "token": "get",
         "frequency": 168,
         "rank": 49,
         "normalised_frequency": 0.0027765841404158264,
         "cumulative_frequency": 0.4317918884077612,
         "_deepnote_index_column": 48
        },
        {
         "token": "up",
         "frequency": 167,
         "rank": 50,
         "normalised_frequency": 0.0027600568538657323,
         "cumulative_frequency": 0.43455194526162694,
         "_deepnote_index_column": 49
        },
        {
         "token": "we",
         "frequency": 166,
         "rank": 51,
         "normalised_frequency": 0.0027435295673156382,
         "cumulative_frequency": 0.4372954748289426,
         "_deepnote_index_column": 50
        },
        {
         "token": "&",
         "frequency": 166,
         "rank": 52,
         "normalised_frequency": 0.0027435295673156382,
         "cumulative_frequency": 0.44003900439625826,
         "_deepnote_index_column": 51
        },
        {
         "token": "no",
         "frequency": 161,
         "rank": 53,
         "normalised_frequency": 0.0026608931345651673,
         "cumulative_frequency": 0.44269989753082345,
         "_deepnote_index_column": 52
        },
        {
         "token": "by",
         "frequency": 157,
         "rank": 54,
         "normalised_frequency": 0.0025947839883647904,
         "cumulative_frequency": 0.4452946815191882,
         "_deepnote_index_column": 53
        },
        {
         "token": "from",
         "frequency": 146,
         "rank": 55,
         "normalised_frequency": 0.002412983836313754,
         "cumulative_frequency": 0.447707665355502,
         "_deepnote_index_column": 54
        },
        {
         "token": "people",
         "frequency": 139,
         "rank": 56,
         "normalised_frequency": 0.0022972928304630944,
         "cumulative_frequency": 0.4500049581859651,
         "_deepnote_index_column": 55
        },
        {
         "token": "can",
         "frequency": 135,
         "rank": 57,
         "normalised_frequency": 0.0022311836842627175,
         "cumulative_frequency": 0.4522361418702278,
         "_deepnote_index_column": 56
        },
        {
         "token": "how",
         "frequency": 135,
         "rank": 58,
         "normalised_frequency": 0.0022311836842627175,
         "cumulative_frequency": 0.45446732555449054,
         "_deepnote_index_column": 57
        },
        {
         "token": "would",
         "frequency": 132,
         "rank": 59,
         "normalised_frequency": 0.0021816018246124352,
         "cumulative_frequency": 0.45664892737910295,
         "_deepnote_index_column": 58
        },
        {
         "token": "as",
         "frequency": 129,
         "rank": 60,
         "normalised_frequency": 0.0021320199649621525,
         "cumulative_frequency": 0.4587809473440651,
         "_deepnote_index_column": 59
        },
        {
         "token": "or",
         "frequency": 126,
         "rank": 61,
         "normalised_frequency": 0.0020824381053118697,
         "cumulative_frequency": 0.460863385449377,
         "_deepnote_index_column": 60
        },
        {
         "token": ":",
         "frequency": 124,
         "rank": 62,
         "normalised_frequency": 0.0020493835322116815,
         "cumulative_frequency": 0.4629127689815887,
         "_deepnote_index_column": 61
        },
        {
         "token": "an",
         "frequency": 120,
         "rank": 63,
         "normalised_frequency": 0.0019832743860113047,
         "cumulative_frequency": 0.4648960433676,
         "_deepnote_index_column": 62
        },
        {
         "token": "who",
         "frequency": 117,
         "rank": 64,
         "normalised_frequency": 0.0019336925263610221,
         "cumulative_frequency": 0.466829735893961,
         "_deepnote_index_column": 63
        },
        {
         "token": "there",
         "frequency": 116,
         "rank": 65,
         "normalised_frequency": 0.0019171652398109278,
         "cumulative_frequency": 0.46874690113377193,
         "_deepnote_index_column": 64
        },
        {
         "token": "one",
         "frequency": 115,
         "rank": 66,
         "normalised_frequency": 0.0019006379532608337,
         "cumulative_frequency": 0.4706475390870328,
         "_deepnote_index_column": 65
        },
        {
         "token": "now",
         "frequency": 110,
         "rank": 67,
         "normalised_frequency": 0.0018180015205103625,
         "cumulative_frequency": 0.47246554060754314,
         "_deepnote_index_column": 66
        },
        {
         "token": "his",
         "frequency": 109,
         "rank": 68,
         "normalised_frequency": 0.0018014742339602684,
         "cumulative_frequency": 0.4742670148415034,
         "_deepnote_index_column": 67
        },
        {
         "token": "has",
         "frequency": 108,
         "rank": 69,
         "normalised_frequency": 0.0017849469474101741,
         "cumulative_frequency": 0.47605196178891357,
         "_deepnote_index_column": 68
        },
        {
         "token": "cannot",
         "frequency": 106,
         "rank": 70,
         "normalised_frequency": 0.0017518923743099857,
         "cumulative_frequency": 0.4778038541632236,
         "_deepnote_index_column": 69
        },
        {
         "token": "want",
         "frequency": 105,
         "rank": 71,
         "normalised_frequency": 0.0017353650877598916,
         "cumulative_frequency": 0.4795392192509835,
         "_deepnote_index_column": 70
        },
        {
         "token": "know",
         "frequency": 101,
         "rank": 72,
         "normalised_frequency": 0.0016692559415595147,
         "cumulative_frequency": 0.481208475192543,
         "_deepnote_index_column": 71
        },
        {
         "token": "her",
         "frequency": 98,
         "rank": 73,
         "normalised_frequency": 0.0016196740819092322,
         "cumulative_frequency": 0.4828281492744522,
         "_deepnote_index_column": 72
        },
        {
         "token": "going",
         "frequency": 97,
         "rank": 74,
         "normalised_frequency": 0.0016031467953591379,
         "cumulative_frequency": 0.48443129606981133,
         "_deepnote_index_column": 73
        },
        {
         "token": "she",
         "frequency": 97,
         "rank": 75,
         "normalised_frequency": 0.0016031467953591379,
         "cumulative_frequency": 0.48603444286517045,
         "_deepnote_index_column": 74
        },
        {
         "token": "think",
         "frequency": 97,
         "rank": 76,
         "normalised_frequency": 0.0016031467953591379,
         "cumulative_frequency": 0.48763758966052956,
         "_deepnote_index_column": 75
        },
        {
         "token": "did",
         "frequency": 95,
         "rank": 77,
         "normalised_frequency": 0.0015700922222589495,
         "cumulative_frequency": 0.4892076818827885,
         "_deepnote_index_column": 76
        },
        {
         "token": "been",
         "frequency": 94,
         "rank": 78,
         "normalised_frequency": 0.0015535649357088554,
         "cumulative_frequency": 0.49076124681849737,
         "_deepnote_index_column": 77
        },
        {
         "token": "why",
         "frequency": 90,
         "rank": 79,
         "normalised_frequency": 0.0014874557895084785,
         "cumulative_frequency": 0.49224870260800585,
         "_deepnote_index_column": 78
        },
        {
         "token": "some",
         "frequency": 89,
         "rank": 80,
         "normalised_frequency": 0.0014709285029583844,
         "cumulative_frequency": 0.49371963111096423,
         "_deepnote_index_column": 79
        },
        {
         "token": "really",
         "frequency": 88,
         "rank": 81,
         "normalised_frequency": 0.00145440121640829,
         "cumulative_frequency": 0.4951740323273725,
         "_deepnote_index_column": 80
        },
        {
         "token": "go",
         "frequency": 88,
         "rank": 82,
         "normalised_frequency": 0.00145440121640829,
         "cumulative_frequency": 0.4966284335437808,
         "_deepnote_index_column": 81
        },
        {
         "token": "time",
         "frequency": 87,
         "rank": 83,
         "normalised_frequency": 0.001437873929858196,
         "cumulative_frequency": 0.49806630747363895,
         "_deepnote_index_column": 82
        },
        {
         "token": "day",
         "frequency": 85,
         "rank": 84,
         "normalised_frequency": 0.0014048193567580075,
         "cumulative_frequency": 0.49947112683039696,
         "_deepnote_index_column": 83
        },
        {
         "token": "because",
         "frequency": 85,
         "rank": 85,
         "normalised_frequency": 0.0014048193567580075,
         "cumulative_frequency": 0.5008759461871549,
         "_deepnote_index_column": 84
        },
        {
         "token": "even",
         "frequency": 84,
         "rank": 86,
         "normalised_frequency": 0.0013882920702079132,
         "cumulative_frequency": 0.5022642382573629,
         "_deepnote_index_column": 85
        },
        {
         "token": "got",
         "frequency": 83,
         "rank": 87,
         "normalised_frequency": 0.0013717647836578191,
         "cumulative_frequency": 0.5036360030410207,
         "_deepnote_index_column": 86
        },
        {
         "token": "..",
         "frequency": 82,
         "rank": 88,
         "normalised_frequency": 0.0013552374971077248,
         "cumulative_frequency": 0.5049912405381285,
         "_deepnote_index_column": 87
        },
        {
         "token": "back",
         "frequency": 80,
         "rank": 89,
         "normalised_frequency": 0.0013221829240075364,
         "cumulative_frequency": 0.506313423462136,
         "_deepnote_index_column": 88
        },
        {
         "token": "too",
         "frequency": 79,
         "rank": 90,
         "normalised_frequency": 0.0013056556374574423,
         "cumulative_frequency": 0.5076190790995935,
         "_deepnote_index_column": 89
        },
        {
         "token": "their",
         "frequency": 79,
         "rank": 91,
         "normalised_frequency": 0.0013056556374574423,
         "cumulative_frequency": 0.5089247347370509,
         "_deepnote_index_column": 90
        },
        {
         "token": "/",
         "frequency": 77,
         "rank": 92,
         "normalised_frequency": 0.0012726010643572538,
         "cumulative_frequency": 0.5101973358014081,
         "_deepnote_index_column": 91
        },
        {
         "token": "love",
         "frequency": 77,
         "rank": 93,
         "normalised_frequency": 0.0012726010643572538,
         "cumulative_frequency": 0.5114699368657654,
         "_deepnote_index_column": 92
        },
        {
         "token": "over",
         "frequency": 77,
         "rank": 94,
         "normalised_frequency": 0.0012726010643572538,
         "cumulative_frequency": 0.5127425379301226,
         "_deepnote_index_column": 93
        },
        {
         "token": "them",
         "frequency": 77,
         "rank": 95,
         "normalised_frequency": 0.0012726010643572538,
         "cumulative_frequency": 0.5140151389944798,
         "_deepnote_index_column": 94
        },
        {
         "token": "good",
         "frequency": 76,
         "rank": 96,
         "normalised_frequency": 0.0012560737778071595,
         "cumulative_frequency": 0.5152712127722869,
         "_deepnote_index_column": 95
        },
        {
         "token": "off",
         "frequency": 76,
         "rank": 97,
         "normalised_frequency": 0.0012560737778071595,
         "cumulative_frequency": 0.5165272865500941,
         "_deepnote_index_column": 96
        },
        {
         "token": "more",
         "frequency": 75,
         "rank": 98,
         "normalised_frequency": 0.0012395464912570654,
         "cumulative_frequency": 0.5177668330413511,
         "_deepnote_index_column": 97
        },
        {
         "token": "being",
         "frequency": 75,
         "rank": 99,
         "normalised_frequency": 0.0012395464912570654,
         "cumulative_frequency": 0.5190063795326081,
         "_deepnote_index_column": 98
        },
        {
         "token": "still",
         "frequency": 75,
         "rank": 100,
         "normalised_frequency": 0.0012395464912570654,
         "cumulative_frequency": 0.5202459260238651,
         "_deepnote_index_column": 99
        }
       ],
       "rows_bottom": [
        {
         "token": "wi",
         "frequency": 1,
         "rank": 9165,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9983637986316478,
         "_deepnote_index_column": 9164
        },
        {
         "token": "cope",
         "frequency": 1,
         "rank": 9166,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9983803259181979,
         "_deepnote_index_column": 9165
        },
        {
         "token": "#perilous",
         "frequency": 1,
         "rank": 9167,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.998396853204748,
         "_deepnote_index_column": 9166
        },
        {
         "token": "burner",
         "frequency": 1,
         "rank": 9168,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9984133804912981,
         "_deepnote_index_column": 9167
        },
        {
         "token": "#brexit",
         "frequency": 1,
         "rank": 9169,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9984299077778482,
         "_deepnote_index_column": 9168
        },
        {
         "token": "#remain",
         "frequency": 1,
         "rank": 9170,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9984464350643983,
         "_deepnote_index_column": 9169
        },
        {
         "token": "mio",
         "frequency": 1,
         "rank": 9171,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9984629623509484,
         "_deepnote_index_column": 9170
        },
        {
         "token": "17.2",
         "frequency": 1,
         "rank": 9172,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9984794896374986,
         "_deepnote_index_column": 9171
        },
        {
         "token": "mat",
         "frequency": 1,
         "rank": 9173,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9984960169240487,
         "_deepnote_index_column": 9172
        },
        {
         "token": "request",
         "frequency": 1,
         "rank": 9174,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9985125442105988,
         "_deepnote_index_column": 9173
        },
        {
         "token": "kittens",
         "frequency": 1,
         "rank": 9175,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9985290714971489,
         "_deepnote_index_column": 9174
        },
        {
         "token": "involvement",
         "frequency": 1,
         "rank": 9176,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.998545598783699,
         "_deepnote_index_column": 9175
        },
        {
         "token": "kal",
         "frequency": 1,
         "rank": 9177,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9985621260702491,
         "_deepnote_index_column": 9176
        },
        {
         "token": "pk",
         "frequency": 1,
         "rank": 9178,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9985786533567992,
         "_deepnote_index_column": 9177
        },
        {
         "token": "crucial",
         "frequency": 1,
         "rank": 9179,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9985951806433493,
         "_deepnote_index_column": 9178
        },
        {
         "token": "legally",
         "frequency": 1,
         "rank": 9180,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9986117079298994,
         "_deepnote_index_column": 9179
        },
        {
         "token": "#fallsongs",
         "frequency": 1,
         "rank": 9181,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9986282352164495,
         "_deepnote_index_column": 9180
        },
        {
         "token": "chills",
         "frequency": 1,
         "rank": 9182,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9986447625029996,
         "_deepnote_index_column": 9181
        },
        {
         "token": "amaity",
         "frequency": 1,
         "rank": 9183,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9986612897895497,
         "_deepnote_index_column": 9182
        },
        {
         "token": "ir",
         "frequency": 1,
         "rank": 9184,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9986778170760998,
         "_deepnote_index_column": 9183
        },
        {
         "token": "vas",
         "frequency": 1,
         "rank": 9185,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9986943443626499,
         "_deepnote_index_column": 9184
        },
        {
         "token": "glance",
         "frequency": 1,
         "rank": 9186,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9987108716492,
         "_deepnote_index_column": 9185
        },
        {
         "token": "cave",
         "frequency": 1,
         "rank": 9187,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9987273989357501,
         "_deepnote_index_column": 9186
        },
        {
         "token": "logical",
         "frequency": 1,
         "rank": 9188,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9987439262223002,
         "_deepnote_index_column": 9187
        },
        {
         "token": "visceral-not",
         "frequency": 1,
         "rank": 9189,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9987604535088503,
         "_deepnote_index_column": 9188
        },
        {
         "token": "rational",
         "frequency": 1,
         "rank": 9190,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9987769807954004,
         "_deepnote_index_column": 9189
        },
        {
         "token": "controlled",
         "frequency": 1,
         "rank": 9191,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9987935080819506,
         "_deepnote_index_column": 9190
        },
        {
         "token": "criticise",
         "frequency": 1,
         "rank": 9192,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9988100353685007,
         "_deepnote_index_column": 9191
        },
        {
         "token": "pundits",
         "frequency": 1,
         "rank": 9193,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9988265626550508,
         "_deepnote_index_column": 9192
        },
        {
         "token": "damning",
         "frequency": 1,
         "rank": 9194,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9988430899416009,
         "_deepnote_index_column": 9193
        },
        {
         "token": "uttered",
         "frequency": 1,
         "rank": 9195,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.998859617228151,
         "_deepnote_index_column": 9194
        },
        {
         "token": "boshan",
         "frequency": 1,
         "rank": 9196,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9988761445147011,
         "_deepnote_index_column": 9195
        },
        {
         "token": "patton",
         "frequency": 1,
         "rank": 9197,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9988926718012512,
         "_deepnote_index_column": 9196
        },
        {
         "token": "2am",
         "frequency": 1,
         "rank": 9198,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9989091990878013,
         "_deepnote_index_column": 9197
        },
        {
         "token": "wakes",
         "frequency": 1,
         "rank": 9199,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9989257263743514,
         "_deepnote_index_column": 9198
        },
        {
         "token": "yang",
         "frequency": 1,
         "rank": 9200,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9989422536609015,
         "_deepnote_index_column": 9199
        },
        {
         "token": "waits",
         "frequency": 1,
         "rank": 9201,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9989587809474516,
         "_deepnote_index_column": 9200
        },
        {
         "token": "cowan",
         "frequency": 1,
         "rank": 9202,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9989753082340017,
         "_deepnote_index_column": 9201
        },
        {
         "token": "motlop",
         "frequency": 1,
         "rank": 9203,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9989918355205518,
         "_deepnote_index_column": 9202
        },
        {
         "token": "gameing",
         "frequency": 1,
         "rank": 9204,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9990083628071019,
         "_deepnote_index_column": 9203
        },
        {
         "token": "takeing",
         "frequency": 1,
         "rank": 9205,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.999024890093652,
         "_deepnote_index_column": 9204
        },
        {
         "token": "dame",
         "frequency": 1,
         "rank": 9206,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9990414173802021,
         "_deepnote_index_column": 9205
        },
        {
         "token": "clash",
         "frequency": 1,
         "rank": 9207,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9990579446667522,
         "_deepnote_index_column": 9206
        },
        {
         "token": "ðŸ³",
         "frequency": 1,
         "rank": 9208,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9990744719533023,
         "_deepnote_index_column": 9207
        },
        {
         "token": "slipper",
         "frequency": 1,
         "rank": 9209,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9990909992398525,
         "_deepnote_index_column": 9208
        },
        {
         "token": "#whypay",
         "frequency": 1,
         "rank": 9210,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9991075265264026,
         "_deepnote_index_column": 9209
        },
        {
         "token": "hogging",
         "frequency": 1,
         "rank": 9211,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9991240538129527,
         "_deepnote_index_column": 9210
        },
        {
         "token": "#ivebeenbusierwhyamioverwhelmed",
         "frequency": 1,
         "rank": 9212,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9991405810995028,
         "_deepnote_index_column": 9211
        },
        {
         "token": "#dying",
         "frequency": 1,
         "rank": 9213,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9991571083860529,
         "_deepnote_index_column": 9212
        },
        {
         "token": "processed",
         "frequency": 1,
         "rank": 9214,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.999173635672603,
         "_deepnote_index_column": 9213
        },
        {
         "token": "clutter",
         "frequency": 1,
         "rank": 9215,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9991901629591531,
         "_deepnote_index_column": 9214
        },
        {
         "token": "lights",
         "frequency": 1,
         "rank": 9216,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9992066902457032,
         "_deepnote_index_column": 9215
        },
        {
         "token": "marlboro",
         "frequency": 1,
         "rank": 9217,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9992232175322533,
         "_deepnote_index_column": 9216
        },
        {
         "token": "nappy",
         "frequency": 1,
         "rank": 9218,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9992397448188034,
         "_deepnote_index_column": 9217
        },
        {
         "token": "dangerously",
         "frequency": 1,
         "rank": 9219,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9992562721053535,
         "_deepnote_index_column": 9218
        },
        {
         "token": "flexing",
         "frequency": 1,
         "rank": 9220,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9992727993919036,
         "_deepnote_index_column": 9219
        },
        {
         "token": "claws",
         "frequency": 1,
         "rank": 9221,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9992893266784537,
         "_deepnote_index_column": 9220
        },
        {
         "token": "steel",
         "frequency": 1,
         "rank": 9222,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9993058539650038,
         "_deepnote_index_column": 9221
        },
        {
         "token": "trends",
         "frequency": 1,
         "rank": 9223,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9993223812515539,
         "_deepnote_index_column": 9222
        },
        {
         "token": "swift",
         "frequency": 1,
         "rank": 9224,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.999338908538104,
         "_deepnote_index_column": 9223
        },
        {
         "token": "xucqb",
         "frequency": 1,
         "rank": 9225,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9993554358246541,
         "_deepnote_index_column": 9224
        },
        {
         "token": "cinematography",
         "frequency": 1,
         "rank": 9226,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9993719631112042,
         "_deepnote_index_column": 9225
        },
        {
         "token": "backfire",
         "frequency": 1,
         "rank": 9227,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9993884903977543,
         "_deepnote_index_column": 9226
        },
        {
         "token": "popularization",
         "frequency": 1,
         "rank": 9228,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9994050176843045,
         "_deepnote_index_column": 9227
        },
        {
         "token": "sickness",
         "frequency": 1,
         "rank": 9229,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9994215449708546,
         "_deepnote_index_column": 9228
        },
        {
         "token": "gon",
         "frequency": 1,
         "rank": 9230,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9994380722574047,
         "_deepnote_index_column": 9229
        },
        {
         "token": "brad's",
         "frequency": 1,
         "rank": 9231,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9994545995439548,
         "_deepnote_index_column": 9230
        },
        {
         "token": "wondered",
         "frequency": 1,
         "rank": 9232,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9994711268305049,
         "_deepnote_index_column": 9231
        },
        {
         "token": "#jobinterview",
         "frequency": 1,
         "rank": 9233,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.999487654117055,
         "_deepnote_index_column": 9232
        },
        {
         "token": "#interview",
         "frequency": 1,
         "rank": 9234,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9995041814036051,
         "_deepnote_index_column": 9233
        },
        {
         "token": "withdraw",
         "frequency": 1,
         "rank": 9235,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9995207086901552,
         "_deepnote_index_column": 9234
        },
        {
         "token": "#scorpio's",
         "frequency": 1,
         "rank": 9236,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9995372359767053,
         "_deepnote_index_column": 9235
        },
        {
         "token": "bun",
         "frequency": 1,
         "rank": 9237,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9995537632632554,
         "_deepnote_index_column": 9236
        },
        {
         "token": "ncfc",
         "frequency": 1,
         "rank": 9238,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9995702905498055,
         "_deepnote_index_column": 9237
        },
        {
         "token": "er",
         "frequency": 1,
         "rank": 9239,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9995868178363556,
         "_deepnote_index_column": 9238
        },
        {
         "token": "choices",
         "frequency": 1,
         "rank": 9240,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9996033451229057,
         "_deepnote_index_column": 9239
        },
        {
         "token": "awhile",
         "frequency": 1,
         "rank": 9241,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9996198724094558,
         "_deepnote_index_column": 9240
        },
        {
         "token": "mind-shattering",
         "frequency": 1,
         "rank": 9242,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9996363996960059,
         "_deepnote_index_column": 9241
        },
        {
         "token": "patterns",
         "frequency": 1,
         "rank": 9243,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.999652926982556,
         "_deepnote_index_column": 9242
        },
        {
         "token": "adopt",
         "frequency": 1,
         "rank": 9244,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9996694542691061,
         "_deepnote_index_column": 9243
        },
        {
         "token": "#whenwillitstop",
         "frequency": 1,
         "rank": 9245,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9996859815556562,
         "_deepnote_index_column": 9244
        },
        {
         "token": "snarled",
         "frequency": 1,
         "rank": 9246,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9997025088422063,
         "_deepnote_index_column": 9245
        },
        {
         "token": "reyes",
         "frequency": 1,
         "rank": 9247,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9997190361287565,
         "_deepnote_index_column": 9246
        },
        {
         "token": "snarl",
         "frequency": 1,
         "rank": 9248,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9997355634153066,
         "_deepnote_index_column": 9247
        },
        {
         "token": "mooching",
         "frequency": 1,
         "rank": 9249,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9997520907018567,
         "_deepnote_index_column": 9248
        },
        {
         "token": "greedy",
         "frequency": 1,
         "rank": 9250,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9997686179884068,
         "_deepnote_index_column": 9249
        },
        {
         "token": "#managing",
         "frequency": 1,
         "rank": 9251,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9997851452749569,
         "_deepnote_index_column": 9250
        },
        {
         "token": "fbi",
         "frequency": 1,
         "rank": 9252,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.999801672561507,
         "_deepnote_index_column": 9251
        },
        {
         "token": "#howmanymoretimes",
         "frequency": 1,
         "rank": 9253,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9998181998480571,
         "_deepnote_index_column": 9252
        },
        {
         "token": "#robloxgamer",
         "frequency": 1,
         "rank": 9254,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9998347271346072,
         "_deepnote_index_column": 9253
        },
        {
         "token": "gently",
         "frequency": 1,
         "rank": 9255,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9998512544211573,
         "_deepnote_index_column": 9254
        },
        {
         "token": "termianted",
         "frequency": 1,
         "rank": 9256,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9998677817077074,
         "_deepnote_index_column": 9255
        },
        {
         "token": "roblox",
         "frequency": 1,
         "rank": 9257,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9998843089942575,
         "_deepnote_index_column": 9256
        },
        {
         "token": "freezer",
         "frequency": 1,
         "rank": 9258,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9999008362808076,
         "_deepnote_index_column": 9257
        },
        {
         "token": "mints",
         "frequency": 1,
         "rank": 9259,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9999173635673577,
         "_deepnote_index_column": 9258
        },
        {
         "token": "article's",
         "frequency": 1,
         "rank": 9260,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9999338908539078,
         "_deepnote_index_column": 9259
        },
        {
         "token": "fanbase",
         "frequency": 1,
         "rank": 9261,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9999504181404579,
         "_deepnote_index_column": 9260
        },
        {
         "token": "cules",
         "frequency": 1,
         "rank": 9262,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.999966945427008,
         "_deepnote_index_column": 9261
        },
        {
         "token": "madridistas",
         "frequency": 1,
         "rank": 9263,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 0.9999834727135581,
         "_deepnote_index_column": 9262
        },
        {
         "token": "are.wasted",
         "frequency": 1,
         "rank": 9264,
         "normalised_frequency": 0.000016527286550094206,
         "cumulative_frequency": 1.0000000000001081,
         "_deepnote_index_column": 9263
        }
       ]
      },
      "text/plain": "            token  frequency  rank  normalised_frequency  cumulative_frequency\n0           @user       2019     1              0.033369              0.033369\n1               .       1977     2              0.032674              0.066043\n2             the       1519     3              0.025105              0.091148\n3              to       1258     4              0.020791              0.111939\n4               i       1177     5              0.019453              0.131392\n...           ...        ...   ...                   ...                   ...\n9259    article's          1  9260              0.000017              0.999934\n9260      fanbase          1  9261              0.000017              0.999950\n9261        cules          1  9262              0.000017              0.999967\n9262  madridistas          1  9263              0.000017              0.999983\n9263   are.wasted          1  9264              0.000017              1.000000\n\n[9264 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>token</th>\n      <th>frequency</th>\n      <th>rank</th>\n      <th>normalised_frequency</th>\n      <th>cumulative_frequency</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>@user</td>\n      <td>2019</td>\n      <td>1</td>\n      <td>0.033369</td>\n      <td>0.033369</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>.</td>\n      <td>1977</td>\n      <td>2</td>\n      <td>0.032674</td>\n      <td>0.066043</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>the</td>\n      <td>1519</td>\n      <td>3</td>\n      <td>0.025105</td>\n      <td>0.091148</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>to</td>\n      <td>1258</td>\n      <td>4</td>\n      <td>0.020791</td>\n      <td>0.111939</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>i</td>\n      <td>1177</td>\n      <td>5</td>\n      <td>0.019453</td>\n      <td>0.131392</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9259</th>\n      <td>article's</td>\n      <td>1</td>\n      <td>9260</td>\n      <td>0.000017</td>\n      <td>0.999934</td>\n    </tr>\n    <tr>\n      <th>9260</th>\n      <td>fanbase</td>\n      <td>1</td>\n      <td>9261</td>\n      <td>0.000017</td>\n      <td>0.999950</td>\n    </tr>\n    <tr>\n      <th>9261</th>\n      <td>cules</td>\n      <td>1</td>\n      <td>9262</td>\n      <td>0.000017</td>\n      <td>0.999967</td>\n    </tr>\n    <tr>\n      <th>9262</th>\n      <td>madridistas</td>\n      <td>1</td>\n      <td>9263</td>\n      <td>0.000017</td>\n      <td>0.999983</td>\n    </tr>\n    <tr>\n      <th>9263</th>\n      <td>are.wasted</td>\n      <td>1</td>\n      <td>9264</td>\n      <td>0.000017</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>9264 rows Ã— 5 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Type/ Token Ratio\n---\nThe type/ token ratio of is the quotient of number of types (vocabulary size) to number of tokens (text/corpus size). We compute it in the following way. ",
   "metadata": {
    "tags": [],
    "cell_id": "00054-2a4e34bf-3b29-4b52-9f8e-a095d053a117",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00056-4199ec48-921d-462c-b7e4-dac4515502fd",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "ec67b3c2",
    "execution_start": 1622701493721,
    "execution_millis": 5,
    "output_cleared": false,
    "deepnote_cell_type": "code"
   },
   "source": "for dataset in DATASETS:\n    print(f'TTR ({dataset.title()}): {round(len(VOCABULARY[dataset]) / len(CORPUS[dataset]),2)}')",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "text": "TTR (Hate): 0.09\nTTR (Emotion): 0.15\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "A high TTR generally indicates a high degree of lexical variation in the corpus. However, in this context the higher TTR in the emotion dataset might also result from the fact that it is a lot smaller in size than the hate dataset and thus the TTR score is less biased by few very frequently occurring tokens that decrease the TTR score.",
   "metadata": {
    "tags": [],
    "cell_id": "00059-6dc5f797-8118-479c-ace0-8023ac85684c",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Zipf's Law\n---\nZipf's Law says that the frequency of a word is inversely proportional to its rank in the frequency table. Thus, very few words occur very frequently, while the majority of words have very low frequencies. Tyical frequent words are function words, such as prepositions, pronouns, conjunctions and similar words.\n\nLet's visualise Zipf's Law for both of our datasets.",
   "metadata": {
    "cell_id": "00046-7c9fef28-200d-494f-b96d-c48da9560645",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00061-03a45457-c697-453e-9402-fbded2617f28",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "df912ae0",
    "execution_start": 1622701493728,
    "execution_millis": 6,
    "output_cleared": true,
    "deepnote_cell_type": "code"
   },
   "source": "def visualise_zipf(dataset, log = False):\n    if log:\n        x = np.log(VOCABULARY[dataset]['rank'])\n        y = np.log(VOCABULARY[dataset]['frequency'])\n    else: \n        x = VOCABULARY[dataset]['rank']\n        y = VOCABULARY[dataset]['frequency']\n\n    fig, ax = plt.subplots(ncols=2, figsize=(15,6))\n    ax[0].plot(x, y);\n    ax[0].set_xlabel('Rank'); ax[0].set_ylabel('Frequency'); ax[0].set_title(f'Frequency of Tokens in {dataset.title()}'); \n    ax[1].plot(VOCABULARY[dataset]['rank'], VOCABULARY[dataset]['cumulative_frequency']);\n    ax[1].set_xlabel('Rank'); ax[1].set_ylabel('Cumulative Frequency'); ax[1].set_title(f'Cumulative Frequency of Tokens in {dataset.title()}'); ",
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00062-1721443e-c444-402c-9ee9-01958b97b2a5",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "6b40ea25",
    "execution_start": 1622701493740,
    "execution_millis": 315,
    "output_cleared": false,
    "deepnote_cell_type": "code"
   },
   "source": "visualise_zipf(dataset='hate', log=False)",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1080x432 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light",
      "image/png": {
       "width": 897,
       "height": 387
      }
     },
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00063-2fc1f4a5-1fb3-4915-862b-b50821204c15",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "f524469b",
    "execution_start": 1622701494045,
    "execution_millis": 286,
    "output_cleared": false,
    "deepnote_cell_type": "code"
   },
   "source": "visualise_zipf(dataset = 'emotion', log = False)",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1080x432 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light",
      "image/png": {
       "width": 897,
       "height": 387
      }
     },
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "# Digression: N-Gram Model\n---\nN-Gram Language models are an important tool in NLP, i.e. used in the context of auto-completion or tools like spell checkers. The idea of the model is rather simple: Given a sequence of words, predict the next word that appears with highest probability. In that sense, N-Gram models are a way of finding the maximum likelihood word after a sequence of previous words. But, how do we find this maximum likelihood word? From the point of probability theory, the probability of a word occuring is the conditional probability of seeing some word, given that we already know that that a sequence of previous words has occurred. However, calculating those probabilites for bigger coropora is computationally infeasible. \n\nHowever, one can simplify the computation. The *k*th order *Markov assumption* states that each element of a sequence of tokens only depends on the *k* immediately preceding elements, such that manual \n\n$$\np(w_i|w_{1}, ...,w_{i-1}) \\approx (w_i|w_{i-k}, ..., w_{i-1})\n$$\n\n",
   "metadata": {
    "cell_id": "00012-f7ed8c9e-4e5c-4499-8cbd-bc465deeb219",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "*Note: For exploring n-gram models we are using the training set of the `hate` dataset.*",
   "metadata": {
    "tags": [],
    "cell_id": "00065-24610fd5-4704-4365-87e2-73994c5015df",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Manual Model Prediction\n---\nBefore using external libraries to implement n-gram models, we wanted to give it a shot and code it out for ourselves in the simplest of all cases, the bigram. In this simple model we iterate over each tokenised tweet in the data pairwise, and while doing so incrementing the counter of seeing word 2, given that we have seen word 1 in a nested dictionary. We can then easily convert those counts into conditional probability and from that choose the word that is maximally likely give some word. A `generate` function is then the natrual extension that consecutively chooses the next most likely word for a sequence of *n* words.",
   "metadata": {
    "tags": [],
    "cell_id": "00065-aac8fc30-0b52-4539-85c5-aabb56acac2d",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00068-60a904b8-bb2c-44fc-8639-22b48bfe3199",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "4c272fef",
    "execution_start": 1622701494355,
    "execution_millis": 193,
    "output_cleared": false,
    "deepnote_cell_type": "code"
   },
   "source": "from nltk import bigrams\nfrom collections import Counter, defaultdict\n\nclass OurBigram:\n    def __init__(self):\n        # initialise empty skeleton structure of model as nested dictionary (initialise all counts to 0)\n        self.model = defaultdict(lambda: defaultdict(lambda: 0))\n    \n    def fit(self, data):\n        # count frequency of co-occurances\n        for sentence in data:\n            for w1, w2 in bigrams(sentence, pad_right=True, pad_left=True):\n                self.model[w1][w2] += 1\n            \n        # transform counts to conditional probabilities\n        for w1 in self.model:\n            total_count = float(sum(self.model[w1].values()))\n            for w2 in self.model[w1]:\n                self.model[w1][w2] /= total_count\n\n    def find_mle(self, word):\n        # for a given word return the word that occurs next with maximum likelihood\n        return max(self.model[word], key=self.model[word].get)\n            \n    def generate(self, word, n):\n        # generate a sequence of n words given an initial word from the bigram model\n        while n >= 0:\n            print(word, end=' ') \n            mle = self.find_mle(word)\n            word = mle\n            n-=1\n\n\nbigram = OurBigram()\nbigram.fit(DATA['processed']['hate']['train_text'])\nbigram.generate('hey', 4)",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "text": "hey that is a woman ",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## NLTK Language Model\n---\nIn this section, we are exploring externally implemented language models from the NLTK library that we assume ot perform overall better, i.e. in the way it deals with unseen tokens. The following lines of code show, how the model is being trained on hte training set of the `hate` data. We finally generate a sample tweet of length ten.",
   "metadata": {
    "tags": [],
    "cell_id": "00068-265e4a33-9227-4fbd-a4c2-713f97a31626",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00058-8d948cde-2e02-4c37-bc16-fbe8682c2d39",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1622701494535,
    "source_hash": "da652d23",
    "tags": [],
    "output_cleared": true,
    "deepnote_cell_type": "code"
   },
   "source": "# imports for n-gram language model\nfrom nltk.lm.preprocessing import padded_everygram_pipeline\nfrom nltk.lm import MLE",
   "execution_count": 36,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00062-8d124715-50b4-43a6-9d89-ea885342ff27",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 12903,
    "execution_start": 1622701494554,
    "source_hash": "41955566",
    "tags": [],
    "output_cleared": true,
    "deepnote_cell_type": "code"
   },
   "source": "# number of grams\nn=5\n\n# split \ntrain, vocab = padded_everygram_pipeline(n, DATA['processed'][\"hate\"][\"train_text\"])\n\n# initialise and fit data\nlm = MLE(n)\nlm.fit(train, vocab)",
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00076-99664b8f-9d0d-4370-932f-da7947884f7b",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 35,
    "execution_start": 1622701507464,
    "source_hash": "ef730c3",
    "tags": [],
    "output_cleared": false,
    "deepnote_cell_type": "code"
   },
   "source": "'hitler ' + ' '.join(lm.generate(10, text_seed=['hitler'], random_seed=10))",
   "execution_count": 38,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 38,
     "data": {
      "text/plain": "'hitler may come back from the grave just to choke merkel'"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "We can see that the model is capable of occational, syntactically correct and plausible, hate speech.",
   "metadata": {
    "tags": [],
    "cell_id": "00068-70f85ac3-5810-42eb-bf59-c1448a264cbe",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "# Digression: Manual Annotations and Inter-Annotator Agreement (IAA)\n---\n*TASK 3*\n\nClassification tasks in ML are concerned with predicting a class membership of some object based on computed features. Just as with any other type of objects of data we are dealing with, there are different ways of predicting these labels. \n\n1. **Explicit Rules**: Defining explicit rules in what instances of features, what label to predict\n\n2. **Unsupervised Learning**: Letting the machine find clusters within the data by itself\n\n3. **Supervised Learning**: Manually enriching the data with additional information through annotation.\n\nDefining explicit decision rules is most of the times infeasible for more complex classfication problems. Likewise, unsupervised learning models in NLP often do not give the wanted results. For this reason, the predominant method for knowledge encoding when dealing with natural language is the supervised learning that involves the process of manual annotation. \n\nManually annotating data means to define some kind of *gold standard*, which the label our model ideally predicts. However, this in itself can be a challenge, since language can be ambigious, and interpretation is often subject of personal opinion. \n\nIn this section we therefore manually annotate a small percentage (100 tweets) of the training corpus in the `hate` dataset and compute metrics to what degree we agreed on class membership. We followed the [Annotation Guidelines](https://github.com/msang/hateval/blob/master/annotation_guidelines.md) as employed by the source of the data ([Final Paper](https://www.aclweb.org/anthology/S19-2007.pdf))\n",
   "metadata": {
    "cell_id": "00082-d445badc-5275-4d02-af41-527b34f6b56b",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Generate IAA Sample\n---\nWe first generate the sample of tweets and corresponding gold standard labels as reported by the source of the data. For ease, we chose the last 100 tweets from the training corpus of the `hate` dataset. The tweets were exported into a separate file in the directory `data/annotations`.",
   "metadata": {
    "tags": [],
    "cell_id": "00091-f47e225f-5246-4e5b-b192-000bb83e5219",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00083-94c0db2e-6605-483e-bc6b-c91fa82efcfa",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1622701507471,
    "source_hash": "70c599fc",
    "tags": [],
    "output_cleared": true,
    "deepnote_cell_type": "code"
   },
   "source": "if GENERATE_IAA_SAMPLE == True:\n    with open('../data/annotations/annotation_sample.txt', 'w') as outfile:\n        for tweet in DATA['raw']['hate']['train_text'][-100:]: # last 100 tweets in hate training set\n            outfile.writelines(tweet + '\\n')\n    with open('../data/annotations/ground_truth_annotation_sample.txt', 'w') as outfile:\n        for label in DATA['raw']['hate']['train_labels'][-100:]:\n            outfile.writelines(str(label) + '\\n')",
   "execution_count": 39,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Without looking at the gold standard labels from the source of the data, each member of the group individually annotated the 100 tweets and uploaded the file into the folder `data/annotations/manual_annotations`. The following section evaluates the results of this annotation.",
   "metadata": {
    "tags": [],
    "cell_id": "00076-603f59db-4850-4afa-833d-d06e1c2eaa3e",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "## Evaluation\n---\nThere exist different metrics for evaluating annotations of multiple annotators, which we will compute within this section. For easy dealing, we read in the manual annotations and load them into a single dataframe, containing both the original tweet, the gold standard label and the four annotated labels by each group member.",
   "metadata": {
    "tags": [],
    "cell_id": "00093-d2583796-19e9-43c4-887a-1e565459a12b",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00085-0c6885fd-8014-4ce7-bfbd-bf43e305bc0a",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 10,
    "execution_start": 1622701507479,
    "source_hash": "27dcf014",
    "tags": [],
    "output_cleared": true,
    "deepnote_cell_type": "code"
   },
   "source": "# compare manual annotations through building dataframe\nannotation_evaluation = pd.DataFrame({'tweets': DATA['raw']['hate']['train_text'][-100:], 'ground_truth': DATA['raw']['hate']['train_labels'][-100:]})\n\nfor filename in os.listdir('../data/annotations/manual_annotations'): # opening manually annotated files\n    with open(f'../data/annotations/manual_annotations/{filename}', 'r') as infile:\n        annotation_evaluation[filename[:-4]] = [int(line.strip()) for line in infile.readlines()]",
   "execution_count": 40,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "cell_id": "00086-60a0157a-ff3a-421b-afc1-6ea25b5459e4",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 41,
    "execution_start": 1622701507491,
    "source_hash": "75b8187d",
    "tags": [],
    "output_cleared": false,
    "deepnote_cell_type": "code"
   },
   "source": "annotation_evaluation",
   "execution_count": 41,
   "outputs": [
    {
     "output_type": "execute_result",
     "execution_count": 41,
     "data": {
      "application/vnd.deepnote.dataframe.v2+json": {
       "row_count": 100,
       "column_count": 6,
       "columns": [
        {
         "name": "tweets",
         "dtype": "object",
         "stats": {
          "unique_count": 100,
          "nan_count": 0,
          "categories": [
           {
            "name": "Cry baby Hollywood Dems Anti-Trump celebs too poor to run as a Mayor to show everyone they can be better politicians than him. Comments? @user no no no no new war under Trump, Europe is still handling the refugees from Obama's wars. Hi Ohio! @user weekend feels",
            "count": 1
           },
           {
            "name": "@user Do I have to fight another bitch ass looking cunt today?",
            "count": 1
           },
           {
            "name": "98 others",
            "count": 98
           }
          ]
         }
        },
        {
         "name": "ground_truth",
         "dtype": "int64",
         "stats": {
          "unique_count": 2,
          "nan_count": 0,
          "min": "0",
          "max": "1",
          "histogram": [
           {
            "bin_start": 0,
            "bin_end": 0.1,
            "count": 57
           },
           {
            "bin_start": 0.1,
            "bin_end": 0.2,
            "count": 0
           },
           {
            "bin_start": 0.2,
            "bin_end": 0.30000000000000004,
            "count": 0
           },
           {
            "bin_start": 0.30000000000000004,
            "bin_end": 0.4,
            "count": 0
           },
           {
            "bin_start": 0.4,
            "bin_end": 0.5,
            "count": 0
           },
           {
            "bin_start": 0.5,
            "bin_end": 0.6000000000000001,
            "count": 0
           },
           {
            "bin_start": 0.6000000000000001,
            "bin_end": 0.7000000000000001,
            "count": 0
           },
           {
            "bin_start": 0.7000000000000001,
            "bin_end": 0.8,
            "count": 0
           },
           {
            "bin_start": 0.8,
            "bin_end": 0.9,
            "count": 0
           },
           {
            "bin_start": 0.9,
            "bin_end": 1,
            "count": 43
           }
          ]
         }
        },
        {
         "name": "nicola_annotations",
         "dtype": "int64",
         "stats": {
          "unique_count": 2,
          "nan_count": 0,
          "min": "0",
          "max": "1",
          "histogram": [
           {
            "bin_start": 0,
            "bin_end": 0.1,
            "count": 58
           },
           {
            "bin_start": 0.1,
            "bin_end": 0.2,
            "count": 0
           },
           {
            "bin_start": 0.2,
            "bin_end": 0.30000000000000004,
            "count": 0
           },
           {
            "bin_start": 0.30000000000000004,
            "bin_end": 0.4,
            "count": 0
           },
           {
            "bin_start": 0.4,
            "bin_end": 0.5,
            "count": 0
           },
           {
            "bin_start": 0.5,
            "bin_end": 0.6000000000000001,
            "count": 0
           },
           {
            "bin_start": 0.6000000000000001,
            "bin_end": 0.7000000000000001,
            "count": 0
           },
           {
            "bin_start": 0.7000000000000001,
            "bin_end": 0.8,
            "count": 0
           },
           {
            "bin_start": 0.8,
            "bin_end": 0.9,
            "count": 0
           },
           {
            "bin_start": 0.9,
            "bin_end": 1,
            "count": 42
           }
          ]
         }
        },
        {
         "name": "hugo_annotations",
         "dtype": "int64",
         "stats": {
          "unique_count": 2,
          "nan_count": 0,
          "min": "0",
          "max": "1",
          "histogram": [
           {
            "bin_start": 0,
            "bin_end": 0.1,
            "count": 85
           },
           {
            "bin_start": 0.1,
            "bin_end": 0.2,
            "count": 0
           },
           {
            "bin_start": 0.2,
            "bin_end": 0.30000000000000004,
            "count": 0
           },
           {
            "bin_start": 0.30000000000000004,
            "bin_end": 0.4,
            "count": 0
           },
           {
            "bin_start": 0.4,
            "bin_end": 0.5,
            "count": 0
           },
           {
            "bin_start": 0.5,
            "bin_end": 0.6000000000000001,
            "count": 0
           },
           {
            "bin_start": 0.6000000000000001,
            "bin_end": 0.7000000000000001,
            "count": 0
           },
           {
            "bin_start": 0.7000000000000001,
            "bin_end": 0.8,
            "count": 0
           },
           {
            "bin_start": 0.8,
            "bin_end": 0.9,
            "count": 0
           },
           {
            "bin_start": 0.9,
            "bin_end": 1,
            "count": 15
           }
          ]
         }
        },
        {
         "name": "mika_annotations",
         "dtype": "int64",
         "stats": {
          "unique_count": 2,
          "nan_count": 0,
          "min": "0",
          "max": "1",
          "histogram": [
           {
            "bin_start": 0,
            "bin_end": 0.1,
            "count": 63
           },
           {
            "bin_start": 0.1,
            "bin_end": 0.2,
            "count": 0
           },
           {
            "bin_start": 0.2,
            "bin_end": 0.30000000000000004,
            "count": 0
           },
           {
            "bin_start": 0.30000000000000004,
            "bin_end": 0.4,
            "count": 0
           },
           {
            "bin_start": 0.4,
            "bin_end": 0.5,
            "count": 0
           },
           {
            "bin_start": 0.5,
            "bin_end": 0.6000000000000001,
            "count": 0
           },
           {
            "bin_start": 0.6000000000000001,
            "bin_end": 0.7000000000000001,
            "count": 0
           },
           {
            "bin_start": 0.7000000000000001,
            "bin_end": 0.8,
            "count": 0
           },
           {
            "bin_start": 0.8,
            "bin_end": 0.9,
            "count": 0
           },
           {
            "bin_start": 0.9,
            "bin_end": 1,
            "count": 37
           }
          ]
         }
        },
        {
         "name": "aidan_annotations",
         "dtype": "int64",
         "stats": {
          "unique_count": 2,
          "nan_count": 0,
          "min": "0",
          "max": "1",
          "histogram": [
           {
            "bin_start": 0,
            "bin_end": 0.1,
            "count": 66
           },
           {
            "bin_start": 0.1,
            "bin_end": 0.2,
            "count": 0
           },
           {
            "bin_start": 0.2,
            "bin_end": 0.30000000000000004,
            "count": 0
           },
           {
            "bin_start": 0.30000000000000004,
            "bin_end": 0.4,
            "count": 0
           },
           {
            "bin_start": 0.4,
            "bin_end": 0.5,
            "count": 0
           },
           {
            "bin_start": 0.5,
            "bin_end": 0.6000000000000001,
            "count": 0
           },
           {
            "bin_start": 0.6000000000000001,
            "bin_end": 0.7000000000000001,
            "count": 0
           },
           {
            "bin_start": 0.7000000000000001,
            "bin_end": 0.8,
            "count": 0
           },
           {
            "bin_start": 0.8,
            "bin_end": 0.9,
            "count": 0
           },
           {
            "bin_start": 0.9,
            "bin_end": 1,
            "count": 34
           }
          ]
         }
        },
        {
         "name": "_deepnote_index_column",
         "dtype": "int64"
        }
       ],
       "rows_top": [
        {
         "tweets": "Cry baby Hollywood Dems Anti-Trump celebs too poor to run as a Mayor to show everyone they can be bâ€¦",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 0
        },
        {
         "tweets": "@user Do I have to fight another bitch ass looking cunt today?",
         "ground_truth": 1,
         "nicola_annotations": 1,
         "hugo_annotations": 0,
         "mika_annotations": 1,
         "aidan_annotations": 1,
         "_deepnote_index_column": 1
        },
        {
         "tweets": "#SouthCarolina has spent millions of dollars to arrest immigrant landscapers, housekeepers #ambassaâ€¦",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 2
        },
        {
         "tweets": "Me trying to flirt- I wanna eat your hot pocket",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 3
        },
        {
         "tweets": "People say, \"Why didn't this or that immigrant for Central or South America apply the proper way anâ€¦",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 4
        },
        {
         "tweets": "I'm not the one to let people profit on my back... I'll break yours and take what's mine ðŸ˜˜",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 1,
         "aidan_annotations": 0,
         "_deepnote_index_column": 5
        },
        {
         "tweets": "#landdegradation undermines the well-being of 3.2 billion people, or â€œtwo-fifths of humanity,â€ drivâ€¦",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 6
        },
        {
         "tweets": "Me trying to flirt- You have really nice eyebrows... I'd like to cum on them to see if they wash off",
         "ground_truth": 1,
         "nicola_annotations": 1,
         "hugo_annotations": 0,
         "mika_annotations": 1,
         "aidan_annotations": 0,
         "_deepnote_index_column": 7
        },
        {
         "tweets": "Two faced Boris now hes on a power trip dosent care about Immigration may is a liar change l don't â€¦",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 8
        },
        {
         "tweets": "Says man who suggested an actress reported an historic rape to gain more work - you're a fully paidâ€¦",
         "ground_truth": 1,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 1,
         "aidan_annotations": 0,
         "_deepnote_index_column": 9
        },
        {
         "tweets": "@user I hope you are not offering them a choice. To hell with the #Tories #SendThemHome",
         "ground_truth": 1,
         "nicola_annotations": 1,
         "hugo_annotations": 1,
         "mika_annotations": 1,
         "aidan_annotations": 1,
         "_deepnote_index_column": 10
        },
        {
         "tweets": "These are not refugees but aggressive male migrants the Med leaders - with exception of @user -wantâ€¦",
         "ground_truth": 1,
         "nicola_annotations": 1,
         "hugo_annotations": 1,
         "mika_annotations": 1,
         "aidan_annotations": 0,
         "_deepnote_index_column": 11
        },
        {
         "tweets": "There are all these illegal immigrant aliens trying to get to Earth, but our 'Space Force' is proteâ€¦",
         "ground_truth": 0,
         "nicola_annotations": 1,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 12
        },
        {
         "tweets": "I feel like post birth abortion should be a thing...",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 13
        },
        {
         "tweets": "UN countries agree on pact to manage mass global migration",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 14
        },
        {
         "tweets": "Girls with blonde hair and dark roots make my cock hard for some reason",
         "ground_truth": 1,
         "nicola_annotations": 1,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 15
        },
        {
         "tweets": "Populists are not anti immigrant or anti immigration or emigration they are PRO rational fair laws â€¦",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 16
        },
        {
         "tweets": "Cases include a twisted paedophile, a lunatic driver and an illegal immigrant who posed as a 16-yeaâ€¦",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 17
        },
        {
         "tweets": "Some cunt at Walmart went full psycho on me saying how she had no fucking space to put her shit bitâ€¦",
         "ground_truth": 1,
         "nicola_annotations": 1,
         "hugo_annotations": 0,
         "mika_annotations": 1,
         "aidan_annotations": 1,
         "_deepnote_index_column": 18
        },
        {
         "tweets": "@user  As you fall over yourselves to welcome Syrian refugees ,homes etc why did you not do it for â€¦",
         "ground_truth": 1,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 1,
         "aidan_annotations": 1,
         "_deepnote_index_column": 19
        },
        {
         "tweets": "Nothing would make me happier than to see you get an STD. #whore #WomenSuck",
         "ground_truth": 1,
         "nicola_annotations": 1,
         "hugo_annotations": 1,
         "mika_annotations": 1,
         "aidan_annotations": 1,
         "_deepnote_index_column": 20
        },
        {
         "tweets": "In the past 4 years personal debt has risen by 90 billion pounds. Much of it spent on trying to livâ€¦",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 21
        },
        {
         "tweets": "Watch: Germany's Real Women's March against migrant violence and Islamism - Free Speech Time - @user",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 22
        },
        {
         "tweets": "@user @user Don't blame refugees for the misery of others. By forcedly removing refugees from theirâ€¦",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 23
        },
        {
         "tweets": "hypnotize synthesize love is a lie like a hole in the sky then you die",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 24
        },
        {
         "tweets": "@user Its not about Trump kids.When are you putting up all those refugees in your home jk???  YOu kâ€¦",
         "ground_truth": 1,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 25
        },
        {
         "tweets": "@user No doubt cory wins most hysterical women his eyes are popping out of his head foaming at the â€¦",
         "ground_truth": 0,
         "nicola_annotations": 1,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 1,
         "_deepnote_index_column": 26
        },
        {
         "tweets": "It's unfortunate that such racist tactics are used against migrant communities. Remember those who â€¦",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 27
        },
        {
         "tweets": "Mandy Manning, one of World Relief's friends and partners @user has just been named 2018 National Tâ€¦",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 28
        },
        {
         "tweets": "#FakeNews Alert!! Flu Vaccine PROPAGANDA Agenda - Immigration = Terrorism REPORT",
         "ground_truth": 1,
         "nicola_annotations": 1,
         "hugo_annotations": 1,
         "mika_annotations": 0,
         "aidan_annotations": 1,
         "_deepnote_index_column": 29
        },
        {
         "tweets": "@user Legally it is rape if you inserted something inside someone without their consent",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 30
        },
        {
         "tweets": "Glad not all men are like that and sad some women are like this...",
         "ground_truth": 1,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 1,
         "_deepnote_index_column": 31
        },
        {
         "tweets": "Don't let the world ending distract you from the fact that you're a hoe.",
         "ground_truth": 0,
         "nicola_annotations": 1,
         "hugo_annotations": 0,
         "mika_annotations": 1,
         "aidan_annotations": 1,
         "_deepnote_index_column": 32
        },
        {
         "tweets": "is this what you would call karma? like how do you as a mexican person vote and support trump, haveâ€¦",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 1,
         "aidan_annotations": 0,
         "_deepnote_index_column": 33
        },
        {
         "tweets": "@user Let me check your ass out with my cock",
         "ground_truth": 1,
         "nicola_annotations": 1,
         "hugo_annotations": 0,
         "mika_annotations": 1,
         "aidan_annotations": 1,
         "_deepnote_index_column": 34
        },
        {
         "tweets": "People in airport bars always wanna tell you their life stories... STFU Bill, IDGAF about your stupâ€¦",
         "ground_truth": 1,
         "nicola_annotations": 1,
         "hugo_annotations": 0,
         "mika_annotations": 1,
         "aidan_annotations": 0,
         "_deepnote_index_column": 35
        },
        {
         "tweets": "Iâ€™ll still fuck a stupid Bitch up tho",
         "ground_truth": 1,
         "nicola_annotations": 1,
         "hugo_annotations": 0,
         "mika_annotations": 1,
         "aidan_annotations": 0,
         "_deepnote_index_column": 36
        },
        {
         "tweets": "When someone tries to threaten me",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 37
        },
        {
         "tweets": "If this is implemented well, could be good news for Philadelphians.",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 38
        },
        {
         "tweets": "If you really wanna know what someone you're fucking thinks about you, make them show you how you'râ€¦",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 39
        },
        {
         "tweets": "@user stupid women fuck up my life #WomenSuck",
         "ground_truth": 1,
         "nicola_annotations": 1,
         "hugo_annotations": 1,
         "mika_annotations": 1,
         "aidan_annotations": 1,
         "_deepnote_index_column": 40
        },
        {
         "tweets": "@user USA should stop trading with Mexico, if they dont stop the refugees.",
         "ground_truth": 1,
         "nicola_annotations": 1,
         "hugo_annotations": 1,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 41
        },
        {
         "tweets": "If you have to ask why #WomenSuck you're obviously a woman.... And you suck.... #subtweet",
         "ground_truth": 1,
         "nicola_annotations": 1,
         "hugo_annotations": 1,
         "mika_annotations": 1,
         "aidan_annotations": 1,
         "_deepnote_index_column": 42
        },
        {
         "tweets": "@user @user Where are you getting #NotAllMen from? I took issue with the fact they don't explain thâ€¦",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 43
        },
        {
         "tweets": "@user The difference is you promote being a slut you dumb bitch you should go fuck yourself and stiâ€¦",
         "ground_truth": 1,
         "nicola_annotations": 1,
         "hugo_annotations": 0,
         "mika_annotations": 1,
         "aidan_annotations": 1,
         "_deepnote_index_column": 44
        },
        {
         "tweets": "@user weird as fuck cuz women suck. #YouSuck",
         "ground_truth": 1,
         "nicola_annotations": 1,
         "hugo_annotations": 1,
         "mika_annotations": 1,
         "aidan_annotations": 1,
         "_deepnote_index_column": 45
        },
        {
         "tweets": "The blue wave is coming if we don't build that damn wall. #BuildThatWall & #MAGA",
         "ground_truth": 1,
         "nicola_annotations": 0,
         "hugo_annotations": 1,
         "mika_annotations": 1,
         "aidan_annotations": 0,
         "_deepnote_index_column": 46
        },
        {
         "tweets": "People that hate on you that you've done nothing to and don't know you are just jealous of you... Eâ€¦",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 47
        },
        {
         "tweets": "When the rival lemonade stand starts stealin your business",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 48
        },
        {
         "tweets": "@user let's get weird! Summertime baby! #FuckBitches",
         "ground_truth": 1,
         "nicola_annotations": 1,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 1,
         "_deepnote_index_column": 49
        },
        {
         "tweets": "WHO.. ARE. YOOUU? This is not mario kart. You are no princess peach. Get your skank ass up out my lâ€¦",
         "ground_truth": 1,
         "nicola_annotations": 1,
         "hugo_annotations": 0,
         "mika_annotations": 1,
         "aidan_annotations": 1,
         "_deepnote_index_column": 50
        },
        {
         "tweets": "Boo, you sweaty whore",
         "ground_truth": 1,
         "nicola_annotations": 1,
         "hugo_annotations": 0,
         "mika_annotations": 1,
         "aidan_annotations": 1,
         "_deepnote_index_column": 51
        },
        {
         "tweets": "Excellent.Since we can't separate families, lock all their asses up until a judge can deport them.Iâ€¦",
         "ground_truth": 1,
         "nicola_annotations": 1,
         "hugo_annotations": 1,
         "mika_annotations": 1,
         "aidan_annotations": 1,
         "_deepnote_index_column": 52
        },
        {
         "tweets": "Just so you know, I'm a righteous Dick Cheney Impersonator, which is not like a thing or anything.",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 53
        },
        {
         "tweets": "RT @user I don't see why drinking and driving is such a big deal. Letting women drive is just as haâ€¦",
         "ground_truth": 1,
         "nicola_annotations": 1,
         "hugo_annotations": 1,
         "mika_annotations": 1,
         "aidan_annotations": 1,
         "_deepnote_index_column": 54
        },
        {
         "tweets": "If Richard Stallman has 1 GB of RAM, and if you have 1 GB of RAM, Richard Stallman has more RAM thaâ€¦",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 55
        },
        {
         "tweets": "We are not all men and women of God in this context, I'm not talking generalization, I'm talking abâ€¦",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 56
        },
        {
         "tweets": "someone: breathes ada: dumb whore cunt slut your moms a hoe kill yourself bitch get shot",
         "ground_truth": 1,
         "nicola_annotations": 1,
         "hugo_annotations": 0,
         "mika_annotations": 1,
         "aidan_annotations": 1,
         "_deepnote_index_column": 57
        },
        {
         "tweets": "From the archives: Daniel Berrigan on refugees, Christ, and the American Dream.",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 58
        },
        {
         "tweets": "Now All These Hoes Talking Bout THEY NEED A GUCCI BITCH BE YOSELF",
         "ground_truth": 1,
         "nicola_annotations": 1,
         "hugo_annotations": 0,
         "mika_annotations": 1,
         "aidan_annotations": 1,
         "_deepnote_index_column": 59
        },
        {
         "tweets": "@user I quite liked the look of the air ram?? And dyson.. but you are right they are a bit steep...â€¦",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 60
        },
        {
         "tweets": "Worldbank reports that in the next 30 years many refugees have to leave her homeland, specially in â€¦",
         "ground_truth": 1,
         "nicola_annotations": 1,
         "hugo_annotations": 1,
         "mika_annotations": 0,
         "aidan_annotations": 1,
         "_deepnote_index_column": 61
        },
        {
         "tweets": "@user Hope one of these crazy ppl assassinate Trump the stupid son of a bitch my free speech he hasâ€¦",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 1,
         "_deepnote_index_column": 62
        },
        {
         "tweets": "This is my most accurate understanding of religion",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 63
        },
        {
         "tweets": "â€œIf this is your definition of journalism, then donâ€™t be suprised when people call you a racially oâ€¦",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 64
        },
        {
         "tweets": "Did you know that Gurmeet Ram Rahim Singh Ji has donated 25 lacs from the Earning of Jattu Engineerâ€¦",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 65
        },
        {
         "tweets": "@user Must take decisive action for sealing borders with B'desh to prevent rampant illegal migratioâ€¦",
         "ground_truth": 1,
         "nicola_annotations": 1,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 66
        },
        {
         "tweets": "@user While ruling a quarter of the Earth the British still lived on an Island the size of Michiganâ€¦",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 67
        },
        {
         "tweets": "Canberra is obviously happy to be seen as an ally of Trump and Orban. And to underline multilateralâ€¦",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 68
        },
        {
         "tweets": "i use to get sky at my dads house but his whore girlfriend never use to let me watch it",
         "ground_truth": 1,
         "nicola_annotations": 1,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 1,
         "_deepnote_index_column": 69
        },
        {
         "tweets": "@user why? So you can look like a trashy mess? #WomenSuck",
         "ground_truth": 1,
         "nicola_annotations": 1,
         "hugo_annotations": 1,
         "mika_annotations": 1,
         "aidan_annotations": 1,
         "_deepnote_index_column": 70
        },
        {
         "tweets": "@user LOL, you do dress like a slut :-) you look excellent.It entertains me that you have the sluttâ€¦",
         "ground_truth": 1,
         "nicola_annotations": 1,
         "hugo_annotations": 0,
         "mika_annotations": 1,
         "aidan_annotations": 1,
         "_deepnote_index_column": 71
        },
        {
         "tweets": "@user Not all women deserve respect. Not all men deserve respect. Respect is earned, not deserved. â€¦",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 72
        },
        {
         "tweets": "Fight to stop U.S. Customs and Border Protection from abusing immigrant children. @user #FamiliesBeâ€¦",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 73
        },
        {
         "tweets": "Went to @user stupid bitch put one in upside down one side ways. #wtf Â£6 we'll spent #cunt",
         "ground_truth": 1,
         "nicola_annotations": 1,
         "hugo_annotations": 0,
         "mika_annotations": 1,
         "aidan_annotations": 1,
         "_deepnote_index_column": 74
        },
        {
         "tweets": "Ready for school? @user provides around 54,000 refugee students access to free education through 15â€¦",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 75
        },
        {
         "tweets": "@user @user Steinle, who was murdered by an illegal Mexican immigrant on July 1, 2015.",
         "ground_truth": 1,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 76
        },
        {
         "tweets": "Thank you @user for welcoming and employing Omar and other refugees eager to provide for their famiâ€¦",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 77
        },
        {
         "tweets": "She's nothing but a @user con. She's an illegal immigrant &amp; Slovenian skinhead Nazi B back homeâ€¦",
         "ground_truth": 1,
         "nicola_annotations": 1,
         "hugo_annotations": 1,
         "mika_annotations": 1,
         "aidan_annotations": 1,
         "_deepnote_index_column": 78
        },
        {
         "tweets": "Mexican immigrant niggas when theyâ€™re working at their taco shop and the cops arrive",
         "ground_truth": 1,
         "nicola_annotations": 1,
         "hugo_annotations": 1,
         "mika_annotations": 1,
         "aidan_annotations": 1,
         "_deepnote_index_column": 79
        },
        {
         "tweets": "Now since all Indians been mapped thru Aadhar Card. Flush out illegal immigrants,whose No has grownâ€¦",
         "ground_truth": 1,
         "nicola_annotations": 1,
         "hugo_annotations": 0,
         "mika_annotations": 1,
         "aidan_annotations": 1,
         "_deepnote_index_column": 80
        },
        {
         "tweets": "It's National Kissing Day... So you can all kiss my mutha fuckin ass",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 81
        },
        {
         "tweets": "Seriously. Get these people out of there. If we can't due to current EU or UN directives then we caâ€¦",
         "ground_truth": 1,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 1,
         "aidan_annotations": 0,
         "_deepnote_index_column": 82
        },
        {
         "tweets": "WHO'S THE WHORE NOW YOU PIECE OF SHIT",
         "ground_truth": 1,
         "nicola_annotations": 1,
         "hugo_annotations": 0,
         "mika_annotations": 1,
         "aidan_annotations": 1,
         "_deepnote_index_column": 83
        },
        {
         "tweets": "I'm a couple days late, but you should read this story from @user on the real estate business of imâ€¦",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 84
        },
        {
         "tweets": "When she got you caught up and you're tryna figure out how you're gonna lie your way outta this one",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 85
        },
        {
         "tweets": "Understanding #foodsecurity in the context of #ruraldevelopment and #agriculture is a central part â€¦",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 86
        },
        {
         "tweets": "I am not a refugee but thank you anyways for supporting my thread",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 87
        },
        {
         "tweets": "I really sympathise for the kid at @user DC office who answered my call. I asked him how he feels aâ€¦",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 88
        },
        {
         "tweets": "Son- mom, how did you and dad meet? Mom- he had on gray sweats and his dick print was fleekin so I â€¦",
         "ground_truth": 0,
         "nicola_annotations": 1,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 89
        },
        {
         "tweets": "Immigrant parents of companies like the annual National Homeland Security, trying to the perfect seâ€¦",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 90
        },
        {
         "tweets": "When the gangbang goes horribly wrong",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 91
        },
        {
         "tweets": "RT @user It's April fools day but I clown you bitches every day. Imma take the day off, have a goodâ€¦",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 1,
         "aidan_annotations": 0,
         "_deepnote_index_column": 92
        },
        {
         "tweets": "@user You call it whatever you want -You praise hoes and and women in the wrong moral leaf and attaâ€¦",
         "ground_truth": 1,
         "nicola_annotations": 1,
         "hugo_annotations": 0,
         "mika_annotations": 1,
         "aidan_annotations": 1,
         "_deepnote_index_column": 93
        },
        {
         "tweets": "Happiest of birthdays to the main hoe ðŸ˜ðŸ’ƒðŸ» I hope you have a wonderful day angel ðŸŒ¹ðŸ’ž @user",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 94
        },
        {
         "tweets": "Oooohhhh bitch didn't even listen to the dead kennedys what a cunt lol I'm 34 and hate rap",
         "ground_truth": 0,
         "nicola_annotations": 1,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 1,
         "_deepnote_index_column": 95
        },
        {
         "tweets": "@user Good Luck @user More Americans #WalkAwayFromDemocrat  #WallkAway from OPEN BORDERS Pro illegaâ€¦",
         "ground_truth": 0,
         "nicola_annotations": 1,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 96
        },
        {
         "tweets": "Bitch you can't keep up so stop trying",
         "ground_truth": 1,
         "nicola_annotations": 1,
         "hugo_annotations": 0,
         "mika_annotations": 1,
         "aidan_annotations": 0,
         "_deepnote_index_column": 97
        },
        {
         "tweets": "@user @user @user @user @user @user Japan is always operating under the premise that mass migrationâ€¦",
         "ground_truth": 0,
         "nicola_annotations": 0,
         "hugo_annotations": 0,
         "mika_annotations": 0,
         "aidan_annotations": 0,
         "_deepnote_index_column": 98
        },
        {
         "tweets": "@user hi Best l see someone fucking girl comment bad in your pic.why you not block the bitch girl nâ€¦",
         "ground_truth": 1,
         "nicola_annotations": 1,
         "hugo_annotations": 0,
         "mika_annotations": 1,
         "aidan_annotations": 1,
         "_deepnote_index_column": 99
        }
       ],
       "rows_bottom": null
      },
      "text/plain": "                                               tweets  ground_truth  \\\n0   Cry baby Hollywood Dems Anti-Trump celebs too ...             0   \n1   @user Do I have to fight another bitch ass loo...             1   \n2   #SouthCarolina has spent millions of dollars t...             0   \n3     Me trying to flirt- I wanna eat your hot pocket             0   \n4   People say, \"Why didn't this or that immigrant...             0   \n..                                                ...           ...   \n95  Oooohhhh bitch didn't even listen to the dead ...             0   \n96  @user Good Luck @user More Americans #WalkAway...             0   \n97             Bitch you can't keep up so stop trying             1   \n98  @user @user @user @user @user @user Japan is a...             0   \n99  @user hi Best l see someone fucking girl comme...             1   \n\n    nicola_annotations  hugo_annotations  mika_annotations  aidan_annotations  \n0                    0                 0                 0                  0  \n1                    1                 0                 1                  1  \n2                    0                 0                 0                  0  \n3                    0                 0                 0                  0  \n4                    0                 0                 0                  0  \n..                 ...               ...               ...                ...  \n95                   1                 0                 0                  1  \n96                   1                 0                 0                  0  \n97                   1                 0                 1                  0  \n98                   0                 0                 0                  0  \n99                   1                 0                 1                  1  \n\n[100 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweets</th>\n      <th>ground_truth</th>\n      <th>nicola_annotations</th>\n      <th>hugo_annotations</th>\n      <th>mika_annotations</th>\n      <th>aidan_annotations</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Cry baby Hollywood Dems Anti-Trump celebs too ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>@user Do I have to fight another bitch ass loo...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>#SouthCarolina has spent millions of dollars t...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Me trying to flirt- I wanna eat your hot pocket</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>People say, \"Why didn't this or that immigrant...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>Oooohhhh bitch didn't even listen to the dead ...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>@user Good Luck @user More Americans #WalkAway...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>Bitch you can't keep up so stop trying</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>@user @user @user @user @user @user Japan is a...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>@user hi Best l see someone fucking girl comme...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows Ã— 6 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "cell_id": "00096-97844893-ab52-44a3-b4f0-504c9fa4c326",
    "output_cleared": true,
    "deepnote_to_be_reexecuted": false,
    "source_hash": "b623e53d",
    "execution_start": 1622701507523,
    "execution_millis": 36164307,
    "deepnote_cell_type": "visualization"
   },
   "execution_count": 41,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Classification Report \n---\nOne way of evaluating the annotation is to treat each annotator as a machine learning model that predicted some label. Then comparing the predicted labels with the set gold-standard allows us to compute common evaluation metrics, such as accuarcy, recall and sensitivity and f-scores, in order to evaluate the quality of the annotations in relation to the assumed gold standard.",
   "metadata": {
    "tags": [],
    "cell_id": "00098-f2a0eb96-33d7-475b-9a79-1323acf49f0f",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "#### Nicola",
   "metadata": {
    "tags": [],
    "cell_id": "00083-e9d8e55e-1a1b-4382-ab8f-4f1cd0866c6d",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00083-4d25e078-0d02-4bee-9b12-18997dc029fc",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "bcea21dc",
    "execution_start": 1622701507526,
    "execution_millis": 27,
    "output_cleared": false,
    "deepnote_cell_type": "code"
   },
   "source": "print('#'*23 + ' ' + 'Nicola' + ' ' + '#'*23 + '\\n')    \nprint(pd.DataFrame(confusion_matrix(annotation_evaluation['ground_truth'], annotation_evaluation['nicola_annotations']), columns=['Predicted Non-Hate', 'Predicted Hate'], index=['Non-Hate', 'Hate']))\nprint('\\n')\nprint(classification_report(annotation_evaluation['ground_truth'], annotation_evaluation['nicola_annotations'], target_names=[\"Non-Hate\",\"Hate\"]))",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "text": "####################### Nicola #######################\n\n          Predicted Non-Hate  Predicted Hate\nNon-Hate                  51               6\nHate                       7              36\n\n\n              precision    recall  f1-score   support\n\n    Non-Hate       0.88      0.89      0.89        57\n        Hate       0.86      0.84      0.85        43\n\n    accuracy                           0.87       100\n   macro avg       0.87      0.87      0.87       100\nweighted avg       0.87      0.87      0.87       100\n\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "#### Hugo",
   "metadata": {
    "tags": [],
    "cell_id": "00085-813a7bbe-d384-4cf4-9238-d0f687fb3c35",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00086-ef62264d-da40-4f93-8501-3b48a383c3af",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "50399f0",
    "execution_start": 1622701507541,
    "execution_millis": 67,
    "output_cleared": false,
    "deepnote_cell_type": "code"
   },
   "source": "print('#'*23 + ' ' + 'Hugo' + ' ' + '#'*23 + '\\n')    \nprint(pd.DataFrame(confusion_matrix(annotation_evaluation['ground_truth'], annotation_evaluation['hugo_annotations']), columns=['Predicted Non-Hate', 'Predicted Hate'], index=['Non-Hate', 'Hate']))\nprint('\\n')\nprint(classification_report(annotation_evaluation['ground_truth'], annotation_evaluation['hugo_annotations'], target_names=[\"Non-Hate\",\"Hate\"]))",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "text": "####################### Hugo #######################\n\n          Predicted Non-Hate  Predicted Hate\nNon-Hate                  57               0\nHate                      28              15\n\n\n              precision    recall  f1-score   support\n\n    Non-Hate       0.67      1.00      0.80        57\n        Hate       1.00      0.35      0.52        43\n\n    accuracy                           0.72       100\n   macro avg       0.84      0.67      0.66       100\nweighted avg       0.81      0.72      0.68       100\n\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "#### Mika",
   "metadata": {
    "tags": [],
    "cell_id": "00087-8d24c2ad-703e-4aac-85e2-e9b989611a9b",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00088-7d2e3665-56fb-4202-b1db-ffb761c3aac1",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "af8257d",
    "execution_start": 1622701507563,
    "execution_millis": 45,
    "output_cleared": false,
    "deepnote_cell_type": "code"
   },
   "source": "print('#'*23 + ' ' + 'Mika' + ' ' + '#'*23 + '\\n')    \nprint(pd.DataFrame(confusion_matrix(annotation_evaluation['ground_truth'], annotation_evaluation['mika_annotations']), columns=['Predicted Non-Hate', 'Predicted Hate'], index=['Non-Hate', 'Hate']))\nprint('\\n')\nprint(classification_report(annotation_evaluation['ground_truth'], annotation_evaluation['mika_annotations'], target_names=[\"Non-Hate\",\"Hate\"]))",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "text": "####################### Mika #######################\n\n          Predicted Non-Hate  Predicted Hate\nNon-Hate                  53               4\nHate                      10              33\n\n\n              precision    recall  f1-score   support\n\n    Non-Hate       0.84      0.93      0.88        57\n        Hate       0.89      0.77      0.82        43\n\n    accuracy                           0.86       100\n   macro avg       0.87      0.85      0.85       100\nweighted avg       0.86      0.86      0.86       100\n\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "#### Aidan",
   "metadata": {
    "tags": [],
    "cell_id": "00089-5d316bcb-e369-47e9-b066-5966d455a8b0",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00090-0b4eefc0-45ba-4abc-a33b-60c161143407",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "8b9c4fb5",
    "execution_start": 1622701507581,
    "execution_millis": 28,
    "output_cleared": false,
    "deepnote_cell_type": "code"
   },
   "source": "print('#'*23 + ' ' + 'Aidan' + ' ' + '#'*23 + '\\n')    \nprint(pd.DataFrame(confusion_matrix(annotation_evaluation['ground_truth'], annotation_evaluation['aidan_annotations']), columns=['Predicted Non-Hate', 'Predicted Hate'], index=['Non-Hate', 'Hate']))\nprint('\\n')\nprint(classification_report(annotation_evaluation['ground_truth'], annotation_evaluation['aidan_annotations'], target_names=[\"Non-Hate\",\"Hate\"]))",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "text": "####################### Aidan #######################\n\n          Predicted Non-Hate  Predicted Hate\nNon-Hate                  53               4\nHate                      13              30\n\n\n              precision    recall  f1-score   support\n\n    Non-Hate       0.80      0.93      0.86        57\n        Hate       0.88      0.70      0.78        43\n\n    accuracy                           0.83       100\n   macro avg       0.84      0.81      0.82       100\nweighted avg       0.84      0.83      0.83       100\n\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "In summary, the confusion matrices and classification reports show that the even in a relatively small sample of only 100 tweets and only four different annotators, hate-speech seems to be perceived differently. Within the group, Nicola was most sensitive towards hate speech, meaning that out of all she labelled the most tweets as being hate speech. This resulted in a high recall score on the hate data and an overall balanced prediction. Hugo, in turn only tagged 15 tweets as being hate speech. His insensitivy towards labelling hate speech resulted in a high perfect recall score on non-hate and perfect precision on hate, i.e. whenever he labelled something as hatespeech, there is absolutely no doubt that it is actually hate speech. However, he also falsely predicted a lot of hate-tweets as being non-hate, resulting in a poor recall score on hate tweets. \n\nThe reports show that annotation of language data with regards to the general *state-of-mind* of the author is subject to personal perception. Thus, we have to find ways of agreeing on some gold-standard. The following chapter explores how we can numerically summarise annotations of multiple annotators to agree on target labels.",
   "metadata": {
    "tags": [],
    "cell_id": "00091-7fa4467f-e5fc-46f7-ba68-7b202aebb3ae",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Cohen's Kappa\n---\nCohen's Kappa ($\\kappa$) is an evaluation metric that is used to measure inter-rater reliability for labelling (categorical) items. In NLP it is i.e. used to compare the annotations of a single annotator with the original annotations. In general, Cohen's Kappa is preferred over simple percentage of agreement, since it corrects the score by the agreement that would be expected by pure chance. \nCohen's Kappa values range from  from in the interval $\\kappa \\in [-1,1]$, with larger values indicating higher agreement between two classifications. \n\nThe following code cell computes the Cohen's Kappa score for each annotator using the function `cohen_kappa_score` from `sci-kit learn`.",
   "metadata": {
    "tags": [],
    "cell_id": "00100-37543064-497f-4aee-a766-05b09d59042f",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00084-4c1bc88c-2ab6-4995-aac4-b91a12fad298",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "5461db6d",
    "execution_start": 1622701507593,
    "execution_millis": 20,
    "output_cleared": false,
    "deepnote_cell_type": "code"
   },
   "source": "# compute cohen's kappa score for each annotator\nfor person in list(annotation_evaluation)[-4:]:\n    print(f'{person[:-12].title()}:\\t {round(cohen_kappa_score(annotation_evaluation[\"ground_truth\"], annotation_evaluation[person]),2)}')",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "text": "Nicola:\t 0.73\nHugo:\t 0.38\nMika:\t 0.71\nAidan:\t 0.64\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "The Cohen Kappa scores of the group's annotations suggest a *substantial agreement* with the original labelling, as three out of four of the scores are above 0.61. Hugo's score is less but is still considered *fair*.\n\nOne can summarise, that from the Cohen Kappa scores there is no substantial evidence against the original labelling being invalid.",
   "metadata": {
    "tags": [],
    "cell_id": "00085-3859dad6-3aee-409f-8f10-64929ae41a93",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "### Fleiss Kappa\n---\nFleiss' Kappa is a statistical measure for assessing the reliability of agreement between a fixed number of annotators when labels to a number of classifying items. In contrast to Cohen's Kappa it is metric between multiple annotators and is not only \n\nThe measure calculates the degree of agreement in classification over that which would be expected by chance.",
   "metadata": {
    "tags": [],
    "cell_id": "00095-bb74ed47-c3eb-4c5f-a5e1-5308d395c15e",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00100-0bac4d0e-2e41-4be3-acaa-a5b21dc7476e",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "31b2361f",
    "execution_start": 1622701507662,
    "execution_millis": 9,
    "output_cleared": false,
    "deepnote_cell_type": "code"
   },
   "source": "# fleiss kappa with ground_truth\nannotation_list = []\nfor row_index in range(len(annotation_evaluation)):\n    zero = len([elm for elm in annotation_evaluation.iloc[row_index, 1:] if elm == 0])\n    annotation_list.append([zero, 5-zero])\n\nannotation_table = np.array(annotation_list)\n\nprint(\"Fleiss's K (Including Ground Truth):\", round(fleiss_kappa(annotation_table),2))\n\n# fleiss kappa without ground_truth\nannotation_list = []\nfor row_index in range(len(annotation_evaluation)):\n    zero = len([elm for elm in annotation_evaluation.iloc[row_index, 2:] if elm == 0])\n    annotation_list.append([zero, 4-zero])\n\nannotation_table = np.array(annotation_list)\n\nprint(\"Fleiss's K (Excluding Ground Truth):\", round(fleiss_kappa(annotation_table),2))",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "text": "Fleiss's K (Including Ground Truth): 0.54\nFleiss's K (Excluding Ground Truth): 0.49\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "In both cases, the Fleiss Kappa score can be interpreted as a *moderate agreement*.\n\nThe fact that the kappa score is higher with the ground truth labels being included tells us that the the 3/4 people who are more in agreement with eachother are more in agreement with the original labelling than Hugo's. ",
   "metadata": {
    "tags": [],
    "cell_id": "00102-9f6504f5-08b3-4913-84f4-414ea05a8ab1",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "# Classification\n---\n*TASK 4*\n\nThe final task of the project is to build the classifier both for the binary and the multiclass classification based on the bag-of-words model. It is a classical approach of extracting features from rich langauge in order to make automated predictions. The following general process was followed and implemented in the `build_model` function:\n\n1. **Combining Training and Validation Splits into Development Set**\n\n2. **Construct Pipeline**\n\n3. **GridSearch for Hyperparameter Tuning**\n\n4. **Model Evaluation**\n\nThe first step of the classifcation task combines the training and validation split, into one development set. This is possible, since at a later point in the classification the `GridSearchCV` method is going to run automatic cross-validation in order to identify the best parameters. \n\nWe then build a pipeline that takes the development set as input and consecutively works on the data: Firstly, the raw tokenised data is transformed into a sparse matrix using the `CountVectorizer` class. This creates a sparse matrix of small numeric values in the number of columns being the vocabulary size of the entire development corpus and the number of rows being the number of total tweets in the development set. Once the language data is transformed into numerical attributes, we can continue to work on the data, in order to build a best-performing model. Firstly, we upsample minority classes using the `SMOTE` oversampler, which synthetically creates new datapoints of the minority class by finding patterns in the existing datapoints of that claas. Through `TFidf Transformation` we compute the relevance of a token within some corpus and is a typically used tool in NLP in order to increase the performance of classifiers. Lastly, the pipeline trains a `SGD Classifier`.\n\nWe use `GridSearchCV` to find the parameters that optimise the overall performance of the model we are building. We therefore define several hyperparameters into a dictionary of parameters, that should be evaluated. The grid automatically performs cross validation on the development set in *n=5* splits and returns the model that optimises for `f1_macro` score. In that way, the resulting model will be optimmised for predicting individual classes equally well.",
   "metadata": {
    "cell_id": "00013-fc964c9b-2d90-48f7-93b6-89e1c191c669",
    "tags": [],
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00099-f9b40fcf-5e09-4120-8f5b-00cab15fa2b8",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "a68a1bfc",
    "execution_start": 1622705456407,
    "execution_millis": 1,
    "output_cleared": false,
    "deepnote_cell_type": "code"
   },
   "source": "from sklearn.model_selection import KFold\nfrom imblearn.pipeline import Pipeline\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import GridSearchCV\n\nkf = KFold(n_splits=5, shuffle=False)\n\ndef build_model(dataset):\n    # combining train and validation, because grid search cross validates to find best params\n    X_dev = DATA['processed'][dataset]['train_text'] + DATA['processed'][dataset]['val_text']\n    y_dev = DATA['processed'][dataset]['train_labels'] + DATA['processed'][dataset]['val_labels']\n\n    # building pipeline to build classifier\n    # a) vectorise tokenised tweets into sparse matrix \n    # b) oversampling\n    # c) term frequency inverse document frequency for better performance\n    # d) train SGD classifier \n    classifier = Pipeline([('vect', CountVectorizer(preprocessor=lambda x:x, tokenizer=lambda x:x, stop_words=stopwords.words('english'))),\n                           ('ovs', SMOTE()),\n                           ('tfidf', TfidfTransformer()),\n                           ('clf', SGDClassifier())])\n\n    # hyperparameters to tune\n    parameters = {\n        'vect__max_df': (0.7, 0.9),                # cutoff tokens that appear in more than (100*p)% of tweets\n        'vect__min_df': (0, 0.05),                 # cutoff tokens that appear in less than (100*p)% of tweets\n        'vect__stop_words': [None, 'english'],     # inlude/ exclude stopwords\n        'tfidf__use_idf': (True, False),           # use/ not use tfidf\n        #'tfidf__norm': ('l1', 'l2'),\n        'clf__loss': ['hinge', 'log'],             # loss function of sgd classifier\n        'clf__alpha': (0.00001, 1e-3),\n        #'clf__penalty': ('l2', 'elasticnet'),\n    }\n\n    grid = GridSearchCV(classifier, param_grid = parameters, cv=kf, n_jobs=-1, scoring='f1_macro')\n    grid = grid.fit(X_dev, y_dev) # fit\n\n    print('Found Optimal Parameters!')\n    print(f'Parameters: {grid.best_params_}')\n    print(f'Best Macro F1-Score: {grid.best_score_}')\n\n    return grid",
   "execution_count": 106,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Binary Classification\n---\nWe now use the above-defined function to build our model for the `hate` dataset. We therefore simply run the function with the correct function arguments. The time of computation depends on the number of hyperparameters to tune. \n\n*In the current configuration, model training takes:  $\\sim$400s*",
   "metadata": {
    "tags": [],
    "cell_id": "00100-900128a5-dbf4-4453-b0c0-f940ec3f206c",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00100-05dfbf2c-c788-448e-bac1-a425a720be8c",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "f3f06f31",
    "execution_start": 1622705457484,
    "execution_millis": 697363,
    "output_cleared": false,
    "deepnote_cell_type": "code"
   },
   "source": "hate_model = build_model(dataset = 'hate')",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "text": "Found Optimal Parameters!\nParameters: {'clf__alpha': 1e-05, 'clf__loss': 'log', 'tfidf__use_idf': True, 'vect__max_df': 0.9, 'vect__min_df': 0, 'vect__stop_words': None}\nBest Macro F1-Score: 0.7364209674541285\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "The `GridSearchCV` returned the best-performing model with the given hyperparameters. We now evaluate on the so-far untouched test data to evaluate the final performance of the model.",
   "metadata": {
    "tags": [],
    "cell_id": "00102-d032fefd-bb47-4eee-a002-d86f63c66065",
    "deepnote_cell_type": "markdown"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00102-b0d91fb4-0aff-4c2a-9e80-fabd580d875a",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "2abb931d",
    "execution_start": 1622706154839,
    "execution_millis": 50,
    "output_cleared": false,
    "deepnote_cell_type": "code"
   },
   "source": "# evaluate\nX_test, y_test = DATA['processed']['hate']['test_text'], DATA['processed']['hate']['test_labels']\n\npredictions = hate_model.predict(X_test)\nprint(classification_report(y_test, predictions))",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stdout",
     "text": "              precision    recall  f1-score   support\n\n           0       0.74      0.19      0.30      1718\n           1       0.45      0.91      0.60      1252\n\n    accuracy                           0.49      2970\n   macro avg       0.60      0.55      0.45      2970\nweighted avg       0.62      0.49      0.43      2970\n\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "tags": [],
    "cell_id": "00104-a9772289-d546-4ac1-b026-eca4897176f8",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "b623e53d",
    "execution_start": 1622706154874,
    "execution_millis": 4,
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "execution_count": 108
  },
  {
   "cell_type": "markdown",
   "source": "## Multiclass Classification\n---\nWe train the model for the emotion recognition in a similar fashion by using the above-defined function. We therefore simply run the function with the correct function arguments. The time of computation depends on the number of hyperparameters to tune. \n\n*In the current configuration, model training takes:  $\\sim$200s*",
   "metadata": {
    "tags": [],
    "cell_id": "00102-eb0a2ff3-ae30-4b18-b4aa-0712e0743b98",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00104-dcd713f2-4b2f-4740-ae6f-5fbe31153559",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "20519055",
    "execution_start": 1622706154881,
    "execution_millis": 191112,
    "output_cleared": false,
    "deepnote_cell_type": "code"
   },
   "source": "emotion_model = build_model(dataset = 'emotion')",
   "execution_count": 109,
   "outputs": [
    {
     "name": "stdout",
     "text": "Found Optimal Parameters!\nParameters: {'clf__alpha': 1e-05, 'clf__loss': 'log', 'tfidf__use_idf': True, 'vect__max_df': 0.7, 'vect__min_df': 0, 'vect__stop_words': 'english'}\nBest Macro F1-Score: 0.6143089557291297\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "The `GridSearchCV` returned the best-performing model with the given hyperparameters. We now evaluate on the so-far untouched test data to evaluate the final performance of the model.",
   "metadata": {
    "tags": [],
    "cell_id": "00106-a3a5b8f4-de8c-47a6-9c93-ac156ac366c7",
    "deepnote_cell_type": "markdown"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00100-1923422e-d33e-4d4e-93db-9177324d89f0",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "cabbfb93",
    "execution_start": 1622706345983,
    "execution_millis": 10,
    "output_cleared": false,
    "deepnote_cell_type": "code"
   },
   "source": "# evaluate\nX_test, y_test = DATA['processed']['emotion']['test_text'], DATA['processed']['emotion']['test_labels']\n\npredictions = emotion_model.predict(X_test)\nprint(classification_report(y_test, predictions))",
   "execution_count": 110,
   "outputs": [
    {
     "name": "stdout",
     "text": "              precision    recall  f1-score   support\n\n           0       0.76      0.73      0.75       558\n           1       0.71      0.67      0.69       358\n           2       0.30      0.34      0.32       123\n           3       0.65      0.69      0.67       382\n\n    accuracy                           0.67      1421\n   macro avg       0.60      0.61      0.61      1421\nweighted avg       0.68      0.67      0.67      1421\n\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=7ea65742-831a-48cd-9d56-a22e1ed66c7b' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "912c8bda-48f1-43bf-8bff-0aac9dd9fbcb",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 }
}